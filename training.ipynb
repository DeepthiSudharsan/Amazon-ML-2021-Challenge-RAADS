{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.10","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport csv\nimport matplotlib.pyplot as plt\nfrom sklearn.metrics import accuracy_score\nfrom sklearn.model_selection import train_test_split\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\nimport gc\nimport collections\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"execution_count":1,"outputs":[{"name":"stdout","text":"/kaggle/input/datapart2/y_p2.npy\n/kaggle/input/datapart2/encoding_p2.npy\n/kaggle/input/datapart5/__notebook_source__.ipynb\n/kaggle/input/datapart5/encoding_p5.npy\n/kaggle/input/datapart5/y_p5.npy\n/kaggle/input/datapart3/y_p3.npy\n/kaggle/input/datapart3/encoding_p3.npy\n/kaggle/input/datapart4/encoding_p4.npy\n/kaggle/input/datapart4/__notebook_source__.ipynb\n/kaggle/input/datapart4/y_p4.npy\n/kaggle/input/test-encoding/encoding_test.npy\n/kaggle/input/amazon-ml-challenge-2021-hackerearth/sample_submission.csv\n/kaggle/input/amazon-ml-challenge-2021-hackerearth/train.csv\n/kaggle/input/amazon-ml-challenge-2021-hackerearth/test.csv\n/kaggle/input/datapart1/y_p1.npy\n/kaggle/input/datapart1/encoding_p1.npy\n","output_type":"stream"}]},{"cell_type":"code","source":"with open('../input/datapart1/y_p1.npy', 'rb') as f:\n    y1 = np.load(f)\nwith open('../input/datapart2/y_p2.npy', 'rb') as f:\n    y1 = np.concatenate((y1,np.load(f)))\nwith open('../input/datapart3/y_p3.npy', 'rb') as f:\n    y1 = np.concatenate((y1,np.load(f)))\nwith open('../input/datapart4/y_p4.npy', 'rb') as f:\n    y1 = np.concatenate((y1,np.load(f)))","metadata":{"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"code","source":"label = {}\nfor i,j in enumerate(np.unique(y1)):\n    label[j]=i","metadata":{"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"code","source":"classes = len(np.unique(y1))","metadata":{"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"classes","metadata":{"trusted":true},"execution_count":5,"outputs":[{"execution_count":5,"output_type":"execute_result","data":{"text/plain":"1462"},"metadata":{}}]},{"cell_type":"code","source":"from keras.models import Sequential\nfrom keras.layers import Dense,SpatialDropout1D,MaxPool1D,BatchNormalization, Dropout\nimport tensorflow as tf\n\nmy_callbacks = [\n    tf.keras.callbacks.EarlyStopping(patience=10, min_delta=0.0001),\n    tf.keras.callbacks.ReduceLROnPlateau(\n    monitor='val_loss', factor=0.1, patience=5, verbose=1,\n    mode='auto', min_delta=0.0001)\n]\n\nmodel = Sequential()\nmodel.add(tf.keras.layers.InputLayer(input_shape=(1024,)))\n#model.add(tf.keras.layers.LSTM(512))\nmodel.add(Dense(1024*2, activation='relu'))\n# model.add(Dropout(0.3))\n# model.add(Dense(1536, activation='relu'))\n# model.add(Dropout(0.3))\n#model.add(tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(2048*2)))\nmodel.add(Dense(classes,activation='softmax'))\nmodel.compile(loss='sparse_categorical_crossentropy', optimizer='adam', metrics=['accuracy'])","metadata":{"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"code","source":"del y1","metadata":{"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"code","source":"with open('../input/datapart1/encoding_p1.npy', 'rb') as f:\n    X = np.load(f)\nwith open('../input/datapart2/encoding_p2.npy', 'rb') as f:\n    X = np.concatenate((X,np.load(f)))\n    \nwith open('../input/datapart1/y_p1.npy', 'rb') as f:\n    y1 = np.load(f)\nwith open('../input/datapart2/y_p2.npy', 'rb') as f:\n    y1 = np.concatenate((y1,np.load(f)))","metadata":{"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"code","source":"gc.collect()","metadata":{"trusted":true},"execution_count":9,"outputs":[{"execution_count":9,"output_type":"execute_result","data":{"text/plain":"344"},"metadata":{}}]},{"cell_type":"code","source":"y1 = np.array([label[i] for i in y1])","metadata":{"trusted":true},"execution_count":10,"outputs":[]},{"cell_type":"code","source":"X_train, X_test, y_train, y_test = train_test_split(X, y1, test_size=0.33, random_state=42)","metadata":{"trusted":true},"execution_count":11,"outputs":[]},{"cell_type":"code","source":"del X,y1\ngc.collect()","metadata":{"trusted":true},"execution_count":12,"outputs":[{"execution_count":12,"output_type":"execute_result","data":{"text/plain":"66"},"metadata":{}}]},{"cell_type":"code","source":"X_train = X_train.reshape(X_train.shape[0],X_train.shape[1])\nX_test = X_test.reshape(X_test.shape[0],X_test.shape[1])\nmodel.fit(X_train,y_train,epochs=500,validation_data=(X_test, y_test),batch_size = 128,callbacks=my_callbacks)","metadata":{"trusted":true},"execution_count":13,"outputs":[{"name":"stdout","text":"Epoch 1/500\n5074/5074 [==============================] - 23s 4ms/step - loss: 2.2597 - accuracy: 0.5430 - val_loss: 1.3550 - val_accuracy: 0.6771\nEpoch 2/500\n5074/5074 [==============================] - 20s 4ms/step - loss: 1.2046 - accuracy: 0.7034 - val_loss: 1.2625 - val_accuracy: 0.6982\nEpoch 3/500\n5074/5074 [==============================] - 20s 4ms/step - loss: 1.0055 - accuracy: 0.7432 - val_loss: 1.2313 - val_accuracy: 0.7082\nEpoch 4/500\n5074/5074 [==============================] - 19s 4ms/step - loss: 0.8522 - accuracy: 0.7763 - val_loss: 1.2227 - val_accuracy: 0.7143\nEpoch 5/500\n5074/5074 [==============================] - 20s 4ms/step - loss: 0.7204 - accuracy: 0.8054 - val_loss: 1.2493 - val_accuracy: 0.7143\nEpoch 6/500\n5074/5074 [==============================] - 20s 4ms/step - loss: 0.6127 - accuracy: 0.8306 - val_loss: 1.2882 - val_accuracy: 0.7163\nEpoch 7/500\n5074/5074 [==============================] - 19s 4ms/step - loss: 0.5226 - accuracy: 0.8538 - val_loss: 1.3374 - val_accuracy: 0.7149\nEpoch 8/500\n5074/5074 [==============================] - 20s 4ms/step - loss: 0.4510 - accuracy: 0.8732 - val_loss: 1.3954 - val_accuracy: 0.7137\nEpoch 9/500\n5074/5074 [==============================] - 20s 4ms/step - loss: 0.3970 - accuracy: 0.8886 - val_loss: 1.4552 - val_accuracy: 0.7138\n\nEpoch 00009: ReduceLROnPlateau reducing learning rate to 0.00010000000474974513.\nEpoch 10/500\n5074/5074 [==============================] - 20s 4ms/step - loss: 0.2906 - accuracy: 0.9213 - val_loss: 1.4418 - val_accuracy: 0.7282\nEpoch 11/500\n5074/5074 [==============================] - 20s 4ms/step - loss: 0.2517 - accuracy: 0.9323 - val_loss: 1.4554 - val_accuracy: 0.7282\nEpoch 12/500\n5074/5074 [==============================] - 20s 4ms/step - loss: 0.2399 - accuracy: 0.9366 - val_loss: 1.4661 - val_accuracy: 0.7289\nEpoch 13/500\n5074/5074 [==============================] - 20s 4ms/step - loss: 0.2315 - accuracy: 0.9387 - val_loss: 1.4788 - val_accuracy: 0.7286\nEpoch 14/500\n5074/5074 [==============================] - 20s 4ms/step - loss: 0.2254 - accuracy: 0.9405 - val_loss: 1.4888 - val_accuracy: 0.7285\n\nEpoch 00014: ReduceLROnPlateau reducing learning rate to 1.0000000474974514e-05.\n","output_type":"stream"},{"execution_count":13,"output_type":"execute_result","data":{"text/plain":"<tensorflow.python.keras.callbacks.History at 0x7f76cc11ad90>"},"metadata":{}}]},{"cell_type":"code","source":"model.save('./Model1_1.h5',save_format='h5')","metadata":{"trusted":true},"execution_count":14,"outputs":[]},{"cell_type":"code","source":"# X_test = X_test.reshape(X_test.shape[0],X_test.shape[1])\ny_pred = np.argmax(model.predict(X_test),axis=1)","metadata":{"trusted":true},"execution_count":15,"outputs":[]},{"cell_type":"code","source":"accuracy_score(y_test, y_pred)","metadata":{"trusted":true},"execution_count":16,"outputs":[{"execution_count":16,"output_type":"execute_result","data":{"text/plain":"0.7285052879039393"},"metadata":{}}]},{"cell_type":"code","source":"del X_train, X_test, y_train, y_test\ngc.collect()","metadata":{"trusted":true},"execution_count":17,"outputs":[{"execution_count":17,"output_type":"execute_result","data":{"text/plain":"1479"},"metadata":{}}]},{"cell_type":"code","source":"with open('../input/datapart3/encoding_p3.npy', 'rb') as f:\n    X = np.load(f)\nwith open('../input/datapart4/encoding_p4.npy', 'rb') as f:\n    X = np.concatenate((X,np.load(f)))\nwith open('../input/datapart3/y_p3.npy', 'rb') as f:\n    y1 = np.load(f)\nwith open('../input/datapart4/y_p4.npy', 'rb') as f:\n    y1 = np.concatenate((y1,np.load(f)))","metadata":{"trusted":true},"execution_count":18,"outputs":[]},{"cell_type":"code","source":"y1 = np.array([label[i] for i in y1])","metadata":{"trusted":true},"execution_count":19,"outputs":[]},{"cell_type":"code","source":"X_train, X_test, y_train, y_test = train_test_split(X, y1, test_size=0.33, random_state=42)","metadata":{"trusted":true},"execution_count":20,"outputs":[]},{"cell_type":"code","source":"del X,y1\ngc.collect()","metadata":{"trusted":true},"execution_count":21,"outputs":[{"execution_count":21,"output_type":"execute_result","data":{"text/plain":"120"},"metadata":{}}]},{"cell_type":"code","source":"my_callbacks = [\n    tf.keras.callbacks.EarlyStopping(patience=10, min_delta=0.0001),\n    tf.keras.callbacks.ReduceLROnPlateau(\n    monitor='val_loss', factor=0.1, patience=5, verbose=1,\n    mode='auto', min_delta=0.0001)\n]\n\nX_train = X_train.reshape(X_train.shape[0],X_train.shape[1])\nX_test = X_test.reshape(X_test.shape[0],X_test.shape[1])\nmodel.fit(X_train,y_train,epochs=500,validation_data=(X_test, y_test),batch_size = 128,callbacks=my_callbacks)","metadata":{"trusted":true},"execution_count":22,"outputs":[{"name":"stdout","text":"Epoch 1/500\n5074/5074 [==============================] - 21s 4ms/step - loss: 1.5665 - accuracy: 0.7053 - val_loss: 1.5292 - val_accuracy: 0.7050\nEpoch 2/500\n5074/5074 [==============================] - 20s 4ms/step - loss: 1.4921 - accuracy: 0.7060 - val_loss: 1.4828 - val_accuracy: 0.7042\nEpoch 3/500\n5074/5074 [==============================] - 20s 4ms/step - loss: 1.4478 - accuracy: 0.7065 - val_loss: 1.4537 - val_accuracy: 0.7039\nEpoch 4/500\n5074/5074 [==============================] - 20s 4ms/step - loss: 1.4168 - accuracy: 0.7075 - val_loss: 1.4336 - val_accuracy: 0.7040\nEpoch 5/500\n5074/5074 [==============================] - 19s 4ms/step - loss: 1.3932 - accuracy: 0.7087 - val_loss: 1.4187 - val_accuracy: 0.7042\nEpoch 6/500\n5074/5074 [==============================] - 20s 4ms/step - loss: 1.3737 - accuracy: 0.7104 - val_loss: 1.4068 - val_accuracy: 0.7048\nEpoch 7/500\n5074/5074 [==============================] - 20s 4ms/step - loss: 1.3568 - accuracy: 0.7119 - val_loss: 1.3968 - val_accuracy: 0.7055\nEpoch 8/500\n5074/5074 [==============================] - 20s 4ms/step - loss: 1.3417 - accuracy: 0.7133 - val_loss: 1.3882 - val_accuracy: 0.7061\nEpoch 9/500\n5074/5074 [==============================] - 20s 4ms/step - loss: 1.3279 - accuracy: 0.7148 - val_loss: 1.3806 - val_accuracy: 0.7065\nEpoch 10/500\n5074/5074 [==============================] - 20s 4ms/step - loss: 1.3151 - accuracy: 0.7164 - val_loss: 1.3738 - val_accuracy: 0.7071\nEpoch 11/500\n5074/5074 [==============================] - 20s 4ms/step - loss: 1.3031 - accuracy: 0.7180 - val_loss: 1.3677 - val_accuracy: 0.7076\nEpoch 12/500\n5074/5074 [==============================] - 19s 4ms/step - loss: 1.2919 - accuracy: 0.7195 - val_loss: 1.3621 - val_accuracy: 0.7083\nEpoch 13/500\n5074/5074 [==============================] - 20s 4ms/step - loss: 1.2812 - accuracy: 0.7208 - val_loss: 1.3569 - val_accuracy: 0.7089\nEpoch 14/500\n5074/5074 [==============================] - 20s 4ms/step - loss: 1.2710 - accuracy: 0.7223 - val_loss: 1.3522 - val_accuracy: 0.7093\nEpoch 15/500\n5074/5074 [==============================] - 20s 4ms/step - loss: 1.2613 - accuracy: 0.7236 - val_loss: 1.3477 - val_accuracy: 0.7099\nEpoch 16/500\n5074/5074 [==============================] - 20s 4ms/step - loss: 1.2520 - accuracy: 0.7250 - val_loss: 1.3435 - val_accuracy: 0.7104\nEpoch 17/500\n5074/5074 [==============================] - 20s 4ms/step - loss: 1.2430 - accuracy: 0.7263 - val_loss: 1.3396 - val_accuracy: 0.7109\nEpoch 18/500\n5074/5074 [==============================] - 20s 4ms/step - loss: 1.2344 - accuracy: 0.7277 - val_loss: 1.3360 - val_accuracy: 0.7114\nEpoch 19/500\n5074/5074 [==============================] - 20s 4ms/step - loss: 1.2260 - accuracy: 0.7288 - val_loss: 1.3325 - val_accuracy: 0.7118\nEpoch 20/500\n5074/5074 [==============================] - 20s 4ms/step - loss: 1.2179 - accuracy: 0.7300 - val_loss: 1.3293 - val_accuracy: 0.7121\nEpoch 21/500\n5074/5074 [==============================] - 20s 4ms/step - loss: 1.2100 - accuracy: 0.7313 - val_loss: 1.3260 - val_accuracy: 0.7124\nEpoch 22/500\n5074/5074 [==============================] - 20s 4ms/step - loss: 1.2024 - accuracy: 0.7324 - val_loss: 1.3231 - val_accuracy: 0.7127\nEpoch 23/500\n5074/5074 [==============================] - 20s 4ms/step - loss: 1.1950 - accuracy: 0.7336 - val_loss: 1.3203 - val_accuracy: 0.7131\nEpoch 24/500\n5074/5074 [==============================] - 20s 4ms/step - loss: 1.1877 - accuracy: 0.7347 - val_loss: 1.3175 - val_accuracy: 0.7133\nEpoch 25/500\n5074/5074 [==============================] - 20s 4ms/step - loss: 1.1807 - accuracy: 0.7358 - val_loss: 1.3149 - val_accuracy: 0.7136\nEpoch 26/500\n5074/5074 [==============================] - 20s 4ms/step - loss: 1.1738 - accuracy: 0.7370 - val_loss: 1.3125 - val_accuracy: 0.7139\nEpoch 27/500\n5074/5074 [==============================] - 19s 4ms/step - loss: 1.1670 - accuracy: 0.7380 - val_loss: 1.3101 - val_accuracy: 0.7141\nEpoch 28/500\n5074/5074 [==============================] - 20s 4ms/step - loss: 1.1605 - accuracy: 0.7391 - val_loss: 1.3079 - val_accuracy: 0.7143\nEpoch 29/500\n5074/5074 [==============================] - 20s 4ms/step - loss: 1.1540 - accuracy: 0.7400 - val_loss: 1.3057 - val_accuracy: 0.7146\nEpoch 30/500\n5074/5074 [==============================] - 20s 4ms/step - loss: 1.1477 - accuracy: 0.7411 - val_loss: 1.3037 - val_accuracy: 0.7147\nEpoch 31/500\n5074/5074 [==============================] - 19s 4ms/step - loss: 1.1415 - accuracy: 0.7421 - val_loss: 1.3017 - val_accuracy: 0.7150\nEpoch 32/500\n5074/5074 [==============================] - 21s 4ms/step - loss: 1.1355 - accuracy: 0.7431 - val_loss: 1.2998 - val_accuracy: 0.7152\nEpoch 33/500\n5074/5074 [==============================] - 20s 4ms/step - loss: 1.1295 - accuracy: 0.7440 - val_loss: 1.2979 - val_accuracy: 0.7156\nEpoch 34/500\n5074/5074 [==============================] - 19s 4ms/step - loss: 1.1237 - accuracy: 0.7450 - val_loss: 1.2961 - val_accuracy: 0.7156\nEpoch 35/500\n5074/5074 [==============================] - 20s 4ms/step - loss: 1.1179 - accuracy: 0.7460 - val_loss: 1.2945 - val_accuracy: 0.7157\nEpoch 36/500\n5074/5074 [==============================] - 20s 4ms/step - loss: 1.1123 - accuracy: 0.7469 - val_loss: 1.2928 - val_accuracy: 0.7161\nEpoch 37/500\n5074/5074 [==============================] - 20s 4ms/step - loss: 1.1068 - accuracy: 0.7477 - val_loss: 1.2914 - val_accuracy: 0.7163\nEpoch 38/500\n5074/5074 [==============================] - 20s 4ms/step - loss: 1.1013 - accuracy: 0.7487 - val_loss: 1.2897 - val_accuracy: 0.7165\nEpoch 39/500\n5074/5074 [==============================] - 19s 4ms/step - loss: 1.0959 - accuracy: 0.7496 - val_loss: 1.2882 - val_accuracy: 0.7167\nEpoch 40/500\n5074/5074 [==============================] - 20s 4ms/step - loss: 1.0907 - accuracy: 0.7506 - val_loss: 1.2869 - val_accuracy: 0.7168\nEpoch 41/500\n5074/5074 [==============================] - 20s 4ms/step - loss: 1.0855 - accuracy: 0.7514 - val_loss: 1.2855 - val_accuracy: 0.7170\nEpoch 42/500\n5074/5074 [==============================] - 19s 4ms/step - loss: 1.0804 - accuracy: 0.7524 - val_loss: 1.2841 - val_accuracy: 0.7172\nEpoch 43/500\n5074/5074 [==============================] - 20s 4ms/step - loss: 1.0753 - accuracy: 0.7532 - val_loss: 1.2828 - val_accuracy: 0.7174\nEpoch 44/500\n5074/5074 [==============================] - 20s 4ms/step - loss: 1.0703 - accuracy: 0.7540 - val_loss: 1.2816 - val_accuracy: 0.7175\nEpoch 45/500\n5074/5074 [==============================] - 20s 4ms/step - loss: 1.0654 - accuracy: 0.7548 - val_loss: 1.2805 - val_accuracy: 0.7177\nEpoch 46/500\n5074/5074 [==============================] - 20s 4ms/step - loss: 1.0606 - accuracy: 0.7557 - val_loss: 1.2793 - val_accuracy: 0.7177\nEpoch 47/500\n5074/5074 [==============================] - 20s 4ms/step - loss: 1.0558 - accuracy: 0.7565 - val_loss: 1.2782 - val_accuracy: 0.7180\nEpoch 48/500\n5074/5074 [==============================] - 20s 4ms/step - loss: 1.0511 - accuracy: 0.7575 - val_loss: 1.2771 - val_accuracy: 0.7182\nEpoch 49/500\n5074/5074 [==============================] - 19s 4ms/step - loss: 1.0465 - accuracy: 0.7583 - val_loss: 1.2761 - val_accuracy: 0.7183\nEpoch 50/500\n5074/5074 [==============================] - 20s 4ms/step - loss: 1.0419 - accuracy: 0.7591 - val_loss: 1.2751 - val_accuracy: 0.7183\nEpoch 51/500\n5074/5074 [==============================] - 20s 4ms/step - loss: 1.0373 - accuracy: 0.7598 - val_loss: 1.2741 - val_accuracy: 0.7185\nEpoch 52/500\n5074/5074 [==============================] - 20s 4ms/step - loss: 1.0329 - accuracy: 0.7606 - val_loss: 1.2731 - val_accuracy: 0.7187\nEpoch 53/500\n5074/5074 [==============================] - 20s 4ms/step - loss: 1.0284 - accuracy: 0.7615 - val_loss: 1.2722 - val_accuracy: 0.7188\nEpoch 54/500\n5074/5074 [==============================] - 19s 4ms/step - loss: 1.0241 - accuracy: 0.7622 - val_loss: 1.2713 - val_accuracy: 0.7189\nEpoch 55/500\n5074/5074 [==============================] - 20s 4ms/step - loss: 1.0197 - accuracy: 0.7630 - val_loss: 1.2705 - val_accuracy: 0.7192\nEpoch 56/500\n5074/5074 [==============================] - 20s 4ms/step - loss: 1.0155 - accuracy: 0.7638 - val_loss: 1.2696 - val_accuracy: 0.7192\nEpoch 57/500\n5074/5074 [==============================] - 19s 4ms/step - loss: 1.0112 - accuracy: 0.7646 - val_loss: 1.2688 - val_accuracy: 0.7192\nEpoch 58/500\n5074/5074 [==============================] - 20s 4ms/step - loss: 1.0071 - accuracy: 0.7654 - val_loss: 1.2680 - val_accuracy: 0.7193\nEpoch 59/500\n5074/5074 [==============================] - 20s 4ms/step - loss: 1.0029 - accuracy: 0.7662 - val_loss: 1.2673 - val_accuracy: 0.7196\nEpoch 60/500\n5074/5074 [==============================] - 20s 4ms/step - loss: 0.9988 - accuracy: 0.7669 - val_loss: 1.2665 - val_accuracy: 0.7197\nEpoch 61/500\n5074/5074 [==============================] - 19s 4ms/step - loss: 0.9948 - accuracy: 0.7677 - val_loss: 1.2658 - val_accuracy: 0.7197\nEpoch 62/500\n5074/5074 [==============================] - 21s 4ms/step - loss: 0.9908 - accuracy: 0.7685 - val_loss: 1.2651 - val_accuracy: 0.7198\nEpoch 63/500\n5074/5074 [==============================] - 19s 4ms/step - loss: 0.9868 - accuracy: 0.7692 - val_loss: 1.2645 - val_accuracy: 0.7200\nEpoch 64/500\n5074/5074 [==============================] - 20s 4ms/step - loss: 0.9829 - accuracy: 0.7700 - val_loss: 1.2639 - val_accuracy: 0.7202\nEpoch 65/500\n5074/5074 [==============================] - 20s 4ms/step - loss: 0.9790 - accuracy: 0.7708 - val_loss: 1.2632 - val_accuracy: 0.7202\nEpoch 66/500\n5074/5074 [==============================] - 20s 4ms/step - loss: 0.9752 - accuracy: 0.7715 - val_loss: 1.2626 - val_accuracy: 0.7202\nEpoch 67/500\n5074/5074 [==============================] - 20s 4ms/step - loss: 0.9714 - accuracy: 0.7722 - val_loss: 1.2620 - val_accuracy: 0.7204\nEpoch 68/500\n5074/5074 [==============================] - 20s 4ms/step - loss: 0.9676 - accuracy: 0.7729 - val_loss: 1.2614 - val_accuracy: 0.7204\nEpoch 69/500\n5074/5074 [==============================] - 20s 4ms/step - loss: 0.9638 - accuracy: 0.7736 - val_loss: 1.2609 - val_accuracy: 0.7205\nEpoch 70/500\n5074/5074 [==============================] - 20s 4ms/step - loss: 0.9601 - accuracy: 0.7742 - val_loss: 1.2603 - val_accuracy: 0.7206\nEpoch 71/500\n5074/5074 [==============================] - 20s 4ms/step - loss: 0.9565 - accuracy: 0.7749 - val_loss: 1.2598 - val_accuracy: 0.7206\nEpoch 72/500\n5074/5074 [==============================] - 20s 4ms/step - loss: 0.9528 - accuracy: 0.7756 - val_loss: 1.2594 - val_accuracy: 0.7208\nEpoch 73/500\n5074/5074 [==============================] - 20s 4ms/step - loss: 0.9492 - accuracy: 0.7764 - val_loss: 1.2589 - val_accuracy: 0.7209\nEpoch 74/500\n5074/5074 [==============================] - 20s 4ms/step - loss: 0.9457 - accuracy: 0.7770 - val_loss: 1.2584 - val_accuracy: 0.7211\nEpoch 75/500\n5074/5074 [==============================] - 20s 4ms/step - loss: 0.9421 - accuracy: 0.7777 - val_loss: 1.2579 - val_accuracy: 0.7212\nEpoch 76/500\n5074/5074 [==============================] - 20s 4ms/step - loss: 0.9386 - accuracy: 0.7784 - val_loss: 1.2575 - val_accuracy: 0.7213\nEpoch 77/500\n5074/5074 [==============================] - 21s 4ms/step - loss: 0.9351 - accuracy: 0.7791 - val_loss: 1.2572 - val_accuracy: 0.7213\nEpoch 78/500\n5074/5074 [==============================] - 20s 4ms/step - loss: 0.9317 - accuracy: 0.7799 - val_loss: 1.2567 - val_accuracy: 0.7214\nEpoch 79/500\n5074/5074 [==============================] - 19s 4ms/step - loss: 0.9283 - accuracy: 0.7805 - val_loss: 1.2563 - val_accuracy: 0.7216\nEpoch 80/500\n5074/5074 [==============================] - 20s 4ms/step - loss: 0.9249 - accuracy: 0.7810 - val_loss: 1.2559 - val_accuracy: 0.7217\nEpoch 81/500\n5074/5074 [==============================] - 20s 4ms/step - loss: 0.9215 - accuracy: 0.7819 - val_loss: 1.2555 - val_accuracy: 0.7217\nEpoch 82/500\n5074/5074 [==============================] - 20s 4ms/step - loss: 0.9182 - accuracy: 0.7824 - val_loss: 1.2553 - val_accuracy: 0.7218\nEpoch 83/500\n5074/5074 [==============================] - 20s 4ms/step - loss: 0.9149 - accuracy: 0.7831 - val_loss: 1.2550 - val_accuracy: 0.7219\nEpoch 84/500\n5074/5074 [==============================] - 20s 4ms/step - loss: 0.9116 - accuracy: 0.7838 - val_loss: 1.2546 - val_accuracy: 0.7218\nEpoch 85/500\n5074/5074 [==============================] - 20s 4ms/step - loss: 0.9083 - accuracy: 0.7844 - val_loss: 1.2542 - val_accuracy: 0.7220\nEpoch 86/500\n5074/5074 [==============================] - 20s 4ms/step - loss: 0.9051 - accuracy: 0.7851 - val_loss: 1.2540 - val_accuracy: 0.7221\nEpoch 87/500\n5074/5074 [==============================] - 20s 4ms/step - loss: 0.9019 - accuracy: 0.7858 - val_loss: 1.2537 - val_accuracy: 0.7221\nEpoch 88/500\n5074/5074 [==============================] - 20s 4ms/step - loss: 0.8987 - accuracy: 0.7865 - val_loss: 1.2534 - val_accuracy: 0.7222\nEpoch 89/500\n5074/5074 [==============================] - 20s 4ms/step - loss: 0.8955 - accuracy: 0.7871 - val_loss: 1.2532 - val_accuracy: 0.7222\nEpoch 90/500\n5074/5074 [==============================] - 20s 4ms/step - loss: 0.8924 - accuracy: 0.7876 - val_loss: 1.2529 - val_accuracy: 0.7221\nEpoch 91/500\n5074/5074 [==============================] - 19s 4ms/step - loss: 0.8893 - accuracy: 0.7883 - val_loss: 1.2527 - val_accuracy: 0.7224\nEpoch 92/500\n5074/5074 [==============================] - 20s 4ms/step - loss: 0.8862 - accuracy: 0.7890 - val_loss: 1.2525 - val_accuracy: 0.7225\nEpoch 93/500\n5074/5074 [==============================] - 20s 4ms/step - loss: 0.8831 - accuracy: 0.7896 - val_loss: 1.2523 - val_accuracy: 0.7223\nEpoch 94/500\n5074/5074 [==============================] - 19s 4ms/step - loss: 0.8801 - accuracy: 0.7903 - val_loss: 1.2521 - val_accuracy: 0.7225\nEpoch 95/500\n5074/5074 [==============================] - 21s 4ms/step - loss: 0.8771 - accuracy: 0.7908 - val_loss: 1.2518 - val_accuracy: 0.7226\nEpoch 96/500\n5074/5074 [==============================] - 20s 4ms/step - loss: 0.8741 - accuracy: 0.7913 - val_loss: 1.2516 - val_accuracy: 0.7225\nEpoch 97/500\n5074/5074 [==============================] - 20s 4ms/step - loss: 0.8711 - accuracy: 0.7921 - val_loss: 1.2514 - val_accuracy: 0.7226\nEpoch 98/500\n5074/5074 [==============================] - 20s 4ms/step - loss: 0.8681 - accuracy: 0.7925 - val_loss: 1.2514 - val_accuracy: 0.7227\nEpoch 99/500\n5074/5074 [==============================] - 20s 4ms/step - loss: 0.8652 - accuracy: 0.7932 - val_loss: 1.2512 - val_accuracy: 0.7227\nEpoch 100/500\n5074/5074 [==============================] - 20s 4ms/step - loss: 0.8622 - accuracy: 0.7938 - val_loss: 1.2510 - val_accuracy: 0.7229\nEpoch 101/500\n5074/5074 [==============================] - 20s 4ms/step - loss: 0.8593 - accuracy: 0.7943 - val_loss: 1.2509 - val_accuracy: 0.7229\nEpoch 102/500\n5074/5074 [==============================] - 20s 4ms/step - loss: 0.8565 - accuracy: 0.7949 - val_loss: 1.2508 - val_accuracy: 0.7229\nEpoch 103/500\n5074/5074 [==============================] - 20s 4ms/step - loss: 0.8536 - accuracy: 0.7956 - val_loss: 1.2507 - val_accuracy: 0.7230\nEpoch 104/500\n5074/5074 [==============================] - 20s 4ms/step - loss: 0.8508 - accuracy: 0.7962 - val_loss: 1.2506 - val_accuracy: 0.7230\nEpoch 105/500\n5074/5074 [==============================] - 20s 4ms/step - loss: 0.8479 - accuracy: 0.7967 - val_loss: 1.2505 - val_accuracy: 0.7230\nEpoch 106/500\n5074/5074 [==============================] - 20s 4ms/step - loss: 0.8451 - accuracy: 0.7973 - val_loss: 1.2503 - val_accuracy: 0.7230\nEpoch 107/500\n5074/5074 [==============================] - 20s 4ms/step - loss: 0.8423 - accuracy: 0.7978 - val_loss: 1.2503 - val_accuracy: 0.7233\nEpoch 108/500\n5074/5074 [==============================] - 20s 4ms/step - loss: 0.8396 - accuracy: 0.7985 - val_loss: 1.2502 - val_accuracy: 0.7233\nEpoch 109/500\n5074/5074 [==============================] - 19s 4ms/step - loss: 0.8368 - accuracy: 0.7991 - val_loss: 1.2501 - val_accuracy: 0.7234\nEpoch 110/500\n5074/5074 [==============================] - 20s 4ms/step - loss: 0.8341 - accuracy: 0.7996 - val_loss: 1.2501 - val_accuracy: 0.7234\nEpoch 111/500\n5074/5074 [==============================] - 20s 4ms/step - loss: 0.8314 - accuracy: 0.8002 - val_loss: 1.2500 - val_accuracy: 0.7234\nEpoch 112/500\n5074/5074 [==============================] - 19s 4ms/step - loss: 0.8287 - accuracy: 0.8007 - val_loss: 1.2500 - val_accuracy: 0.7235\nEpoch 113/500\n5074/5074 [==============================] - 20s 4ms/step - loss: 0.8260 - accuracy: 0.8014 - val_loss: 1.2500 - val_accuracy: 0.7236\nEpoch 114/500\n5074/5074 [==============================] - 20s 4ms/step - loss: 0.8233 - accuracy: 0.8019 - val_loss: 1.2500 - val_accuracy: 0.7235\nEpoch 115/500\n5074/5074 [==============================] - 20s 4ms/step - loss: 0.8207 - accuracy: 0.8025 - val_loss: 1.2500 - val_accuracy: 0.7236\nEpoch 116/500\n5074/5074 [==============================] - 20s 4ms/step - loss: 0.8180 - accuracy: 0.8031 - val_loss: 1.2499 - val_accuracy: 0.7237\nEpoch 117/500\n5074/5074 [==============================] - 20s 4ms/step - loss: 0.8154 - accuracy: 0.8037 - val_loss: 1.2499 - val_accuracy: 0.7235\nEpoch 118/500\n5074/5074 [==============================] - 20s 4ms/step - loss: 0.8128 - accuracy: 0.8042 - val_loss: 1.2500 - val_accuracy: 0.7236\nEpoch 119/500\n5074/5074 [==============================] - 20s 4ms/step - loss: 0.8102 - accuracy: 0.8048 - val_loss: 1.2500 - val_accuracy: 0.7237\nEpoch 120/500\n5074/5074 [==============================] - 19s 4ms/step - loss: 0.8076 - accuracy: 0.8052 - val_loss: 1.2500 - val_accuracy: 0.7238\nEpoch 121/500\n5074/5074 [==============================] - 20s 4ms/step - loss: 0.8051 - accuracy: 0.8058 - val_loss: 1.2500 - val_accuracy: 0.7237\n\nEpoch 00121: ReduceLROnPlateau reducing learning rate to 1.0000000656873453e-06.\nEpoch 122/500\n5074/5074 [==============================] - 20s 4ms/step - loss: 0.8006 - accuracy: 0.8070 - val_loss: 1.2500 - val_accuracy: 0.7238\nEpoch 123/500\n5074/5074 [==============================] - 20s 4ms/step - loss: 0.8003 - accuracy: 0.8071 - val_loss: 1.2500 - val_accuracy: 0.7238\nEpoch 124/500\n5074/5074 [==============================] - 20s 4ms/step - loss: 0.8001 - accuracy: 0.8071 - val_loss: 1.2500 - val_accuracy: 0.7238\nEpoch 125/500\n5074/5074 [==============================] - 20s 4ms/step - loss: 0.7998 - accuracy: 0.8072 - val_loss: 1.2500 - val_accuracy: 0.7239\nEpoch 126/500\n5074/5074 [==============================] - 20s 4ms/step - loss: 0.7995 - accuracy: 0.8072 - val_loss: 1.2500 - val_accuracy: 0.7239\n\nEpoch 00126: ReduceLROnPlateau reducing learning rate to 1.0000001111620805e-07.\n","output_type":"stream"},{"execution_count":22,"output_type":"execute_result","data":{"text/plain":"<tensorflow.python.keras.callbacks.History at 0x7f76ff9142d0>"},"metadata":{}}]},{"cell_type":"code","source":"model.save('./Model1_2.h5',save_format='h5')","metadata":{"trusted":true},"execution_count":23,"outputs":[]},{"cell_type":"code","source":"# X_test = X_test.reshape(X_test.shape[0],X_test.shape[1])\n# y_pred = np.argmax(model.predict(X_test),axis=1)","metadata":{"trusted":true},"execution_count":24,"outputs":[]},{"cell_type":"code","source":"# accuracy_score(y_test, np.argmax(model.predict(X_test),axis=1))","metadata":{"trusted":true},"execution_count":25,"outputs":[]},{"cell_type":"code","source":"del X_train, X_test, y_train, y_test\ngc.collect()","metadata":{"trusted":true},"execution_count":26,"outputs":[{"execution_count":26,"output_type":"execute_result","data":{"text/plain":"1880"},"metadata":{}}]},{"cell_type":"code","source":"with open('../input/datapart5/encoding_p5.npy', 'rb') as f:\n    X = np.load(f)\nwith open('../input/datapart5/y_p5.npy', 'rb') as f:\n    y1 = np.load(f)","metadata":{"trusted":true},"execution_count":28,"outputs":[]},{"cell_type":"code","source":"y1 = np.array([label[i] for i in y1])\nX_train, X_test, y_train, y_test = train_test_split(X, y1, test_size=0.33, random_state=42)\ndel X,y1\ngc.collect()\nX_train = X_train.reshape(X_train.shape[0],X_train.shape[1])\nX_test = X_test.reshape(X_test.shape[0],X_test.shape[1])\nmodel.fit(X_train,y_train,epochs=500,validation_data=(X_test, y_test),batch_size = 128,callbacks=my_callbacks)","metadata":{"trusted":true},"execution_count":29,"outputs":[{"name":"stdout","text":"Epoch 1/500\n3304/3304 [==============================] - 14s 4ms/step - loss: 1.0372 - accuracy: 0.7653 - val_loss: 1.0234 - val_accuracy: 0.7665\nEpoch 2/500\n3304/3304 [==============================] - 13s 4ms/step - loss: 1.0369 - accuracy: 0.7653 - val_loss: 1.0232 - val_accuracy: 0.7665\nEpoch 3/500\n3304/3304 [==============================] - 13s 4ms/step - loss: 1.0366 - accuracy: 0.7653 - val_loss: 1.0231 - val_accuracy: 0.7666\nEpoch 4/500\n3304/3304 [==============================] - 13s 4ms/step - loss: 1.0364 - accuracy: 0.7653 - val_loss: 1.0229 - val_accuracy: 0.7666\nEpoch 5/500\n3304/3304 [==============================] - 13s 4ms/step - loss: 1.0361 - accuracy: 0.7653 - val_loss: 1.0227 - val_accuracy: 0.7666\nEpoch 6/500\n3304/3304 [==============================] - 13s 4ms/step - loss: 1.0359 - accuracy: 0.7653 - val_loss: 1.0225 - val_accuracy: 0.7666\nEpoch 7/500\n3304/3304 [==============================] - 13s 4ms/step - loss: 1.0356 - accuracy: 0.7654 - val_loss: 1.0224 - val_accuracy: 0.7666\nEpoch 8/500\n3304/3304 [==============================] - 13s 4ms/step - loss: 1.0353 - accuracy: 0.7654 - val_loss: 1.0222 - val_accuracy: 0.7665\nEpoch 9/500\n3304/3304 [==============================] - 13s 4ms/step - loss: 1.0351 - accuracy: 0.7654 - val_loss: 1.0220 - val_accuracy: 0.7665\nEpoch 10/500\n3304/3304 [==============================] - 13s 4ms/step - loss: 1.0349 - accuracy: 0.7654 - val_loss: 1.0219 - val_accuracy: 0.7666\nEpoch 11/500\n3304/3304 [==============================] - 13s 4ms/step - loss: 1.0346 - accuracy: 0.7654 - val_loss: 1.0217 - val_accuracy: 0.7666\nEpoch 12/500\n3304/3304 [==============================] - 13s 4ms/step - loss: 1.0344 - accuracy: 0.7654 - val_loss: 1.0216 - val_accuracy: 0.7666\nEpoch 13/500\n3304/3304 [==============================] - 13s 4ms/step - loss: 1.0341 - accuracy: 0.7655 - val_loss: 1.0214 - val_accuracy: 0.7667\nEpoch 14/500\n3304/3304 [==============================] - 13s 4ms/step - loss: 1.0339 - accuracy: 0.7655 - val_loss: 1.0213 - val_accuracy: 0.7667\nEpoch 15/500\n3304/3304 [==============================] - 12s 4ms/step - loss: 1.0336 - accuracy: 0.7655 - val_loss: 1.0211 - val_accuracy: 0.7667\nEpoch 16/500\n3304/3304 [==============================] - 13s 4ms/step - loss: 1.0334 - accuracy: 0.7656 - val_loss: 1.0210 - val_accuracy: 0.7667\nEpoch 17/500\n3304/3304 [==============================] - 13s 4ms/step - loss: 1.0332 - accuracy: 0.7656 - val_loss: 1.0208 - val_accuracy: 0.7667\nEpoch 18/500\n3304/3304 [==============================] - 13s 4ms/step - loss: 1.0329 - accuracy: 0.7656 - val_loss: 1.0207 - val_accuracy: 0.7667\nEpoch 19/500\n3304/3304 [==============================] - 13s 4ms/step - loss: 1.0327 - accuracy: 0.7656 - val_loss: 1.0205 - val_accuracy: 0.7668\nEpoch 20/500\n3304/3304 [==============================] - 12s 4ms/step - loss: 1.0325 - accuracy: 0.7657 - val_loss: 1.0204 - val_accuracy: 0.7668\nEpoch 21/500\n3304/3304 [==============================] - 13s 4ms/step - loss: 1.0323 - accuracy: 0.7657 - val_loss: 1.0202 - val_accuracy: 0.7668\nEpoch 22/500\n3304/3304 [==============================] - 13s 4ms/step - loss: 1.0320 - accuracy: 0.7657 - val_loss: 1.0201 - val_accuracy: 0.7668\nEpoch 23/500\n3304/3304 [==============================] - 13s 4ms/step - loss: 1.0318 - accuracy: 0.7657 - val_loss: 1.0200 - val_accuracy: 0.7668\nEpoch 24/500\n3304/3304 [==============================] - 13s 4ms/step - loss: 1.0316 - accuracy: 0.7658 - val_loss: 1.0198 - val_accuracy: 0.7669\nEpoch 25/500\n3304/3304 [==============================] - 13s 4ms/step - loss: 1.0314 - accuracy: 0.7658 - val_loss: 1.0197 - val_accuracy: 0.7668\nEpoch 26/500\n3304/3304 [==============================] - 13s 4ms/step - loss: 1.0311 - accuracy: 0.7658 - val_loss: 1.0195 - val_accuracy: 0.7669\nEpoch 27/500\n3304/3304 [==============================] - 12s 4ms/step - loss: 1.0309 - accuracy: 0.7658 - val_loss: 1.0194 - val_accuracy: 0.7669\nEpoch 28/500\n3304/3304 [==============================] - 13s 4ms/step - loss: 1.0307 - accuracy: 0.7659 - val_loss: 1.0193 - val_accuracy: 0.7670\nEpoch 29/500\n3304/3304 [==============================] - 13s 4ms/step - loss: 1.0305 - accuracy: 0.7659 - val_loss: 1.0191 - val_accuracy: 0.7669\nEpoch 30/500\n3304/3304 [==============================] - 13s 4ms/step - loss: 1.0303 - accuracy: 0.7659 - val_loss: 1.0190 - val_accuracy: 0.7670\nEpoch 31/500\n3304/3304 [==============================] - 13s 4ms/step - loss: 1.0301 - accuracy: 0.7659 - val_loss: 1.0189 - val_accuracy: 0.7670\nEpoch 32/500\n3304/3304 [==============================] - 13s 4ms/step - loss: 1.0299 - accuracy: 0.7660 - val_loss: 1.0188 - val_accuracy: 0.7669\nEpoch 33/500\n3304/3304 [==============================] - 13s 4ms/step - loss: 1.0296 - accuracy: 0.7660 - val_loss: 1.0186 - val_accuracy: 0.7669\nEpoch 34/500\n3304/3304 [==============================] - 13s 4ms/step - loss: 1.0294 - accuracy: 0.7660 - val_loss: 1.0185 - val_accuracy: 0.7670\nEpoch 35/500\n3304/3304 [==============================] - 13s 4ms/step - loss: 1.0292 - accuracy: 0.7660 - val_loss: 1.0184 - val_accuracy: 0.7670\nEpoch 36/500\n3304/3304 [==============================] - 13s 4ms/step - loss: 1.0290 - accuracy: 0.7660 - val_loss: 1.0183 - val_accuracy: 0.7670\nEpoch 37/500\n3304/3304 [==============================] - 13s 4ms/step - loss: 1.0288 - accuracy: 0.7660 - val_loss: 1.0181 - val_accuracy: 0.7670\nEpoch 38/500\n3304/3304 [==============================] - 13s 4ms/step - loss: 1.0286 - accuracy: 0.7660 - val_loss: 1.0180 - val_accuracy: 0.7670\nEpoch 39/500\n3304/3304 [==============================] - 13s 4ms/step - loss: 1.0284 - accuracy: 0.7661 - val_loss: 1.0179 - val_accuracy: 0.7671\nEpoch 40/500\n3304/3304 [==============================] - 13s 4ms/step - loss: 1.0282 - accuracy: 0.7661 - val_loss: 1.0178 - val_accuracy: 0.7670\nEpoch 41/500\n3304/3304 [==============================] - 13s 4ms/step - loss: 1.0280 - accuracy: 0.7661 - val_loss: 1.0176 - val_accuracy: 0.7670\nEpoch 42/500\n3304/3304 [==============================] - 13s 4ms/step - loss: 1.0278 - accuracy: 0.7661 - val_loss: 1.0175 - val_accuracy: 0.7670\nEpoch 43/500\n3304/3304 [==============================] - 13s 4ms/step - loss: 1.0276 - accuracy: 0.7661 - val_loss: 1.0174 - val_accuracy: 0.7670\nEpoch 44/500\n3304/3304 [==============================] - 13s 4ms/step - loss: 1.0274 - accuracy: 0.7661 - val_loss: 1.0173 - val_accuracy: 0.7670\nEpoch 45/500\n3304/3304 [==============================] - 13s 4ms/step - loss: 1.0272 - accuracy: 0.7661 - val_loss: 1.0172 - val_accuracy: 0.7670\nEpoch 46/500\n3304/3304 [==============================] - 13s 4ms/step - loss: 1.0270 - accuracy: 0.7661 - val_loss: 1.0171 - val_accuracy: 0.7670\nEpoch 47/500\n3304/3304 [==============================] - 13s 4ms/step - loss: 1.0268 - accuracy: 0.7661 - val_loss: 1.0170 - val_accuracy: 0.7670\nEpoch 48/500\n3304/3304 [==============================] - 13s 4ms/step - loss: 1.0266 - accuracy: 0.7662 - val_loss: 1.0168 - val_accuracy: 0.7670\nEpoch 49/500\n3304/3304 [==============================] - 13s 4ms/step - loss: 1.0264 - accuracy: 0.7662 - val_loss: 1.0167 - val_accuracy: 0.7670\nEpoch 50/500\n3304/3304 [==============================] - 12s 4ms/step - loss: 1.0262 - accuracy: 0.7662 - val_loss: 1.0166 - val_accuracy: 0.7670\nEpoch 51/500\n3304/3304 [==============================] - 13s 4ms/step - loss: 1.0260 - accuracy: 0.7662 - val_loss: 1.0165 - val_accuracy: 0.7670\nEpoch 52/500\n3304/3304 [==============================] - 13s 4ms/step - loss: 1.0259 - accuracy: 0.7662 - val_loss: 1.0164 - val_accuracy: 0.7670\nEpoch 53/500\n3304/3304 [==============================] - 13s 4ms/step - loss: 1.0257 - accuracy: 0.7663 - val_loss: 1.0163 - val_accuracy: 0.7670\nEpoch 54/500\n3304/3304 [==============================] - 13s 4ms/step - loss: 1.0255 - accuracy: 0.7663 - val_loss: 1.0162 - val_accuracy: 0.7670\nEpoch 55/500\n3304/3304 [==============================] - 12s 4ms/step - loss: 1.0253 - accuracy: 0.7663 - val_loss: 1.0161 - val_accuracy: 0.7671\nEpoch 56/500\n3304/3304 [==============================] - 13s 4ms/step - loss: 1.0251 - accuracy: 0.7663 - val_loss: 1.0160 - val_accuracy: 0.7670\nEpoch 57/500\n3304/3304 [==============================] - 13s 4ms/step - loss: 1.0249 - accuracy: 0.7663 - val_loss: 1.0159 - val_accuracy: 0.7670\nEpoch 58/500\n3304/3304 [==============================] - 13s 4ms/step - loss: 1.0247 - accuracy: 0.7663 - val_loss: 1.0157 - val_accuracy: 0.7671\nEpoch 59/500\n3304/3304 [==============================] - 13s 4ms/step - loss: 1.0245 - accuracy: 0.7664 - val_loss: 1.0156 - val_accuracy: 0.7671\nEpoch 60/500\n3304/3304 [==============================] - 13s 4ms/step - loss: 1.0244 - accuracy: 0.7664 - val_loss: 1.0155 - val_accuracy: 0.7670\nEpoch 61/500\n3304/3304 [==============================] - 13s 4ms/step - loss: 1.0242 - accuracy: 0.7664 - val_loss: 1.0154 - val_accuracy: 0.7671\nEpoch 62/500\n3304/3304 [==============================] - 13s 4ms/step - loss: 1.0240 - accuracy: 0.7664 - val_loss: 1.0153 - val_accuracy: 0.7671\nEpoch 63/500\n3304/3304 [==============================] - 13s 4ms/step - loss: 1.0238 - accuracy: 0.7664 - val_loss: 1.0152 - val_accuracy: 0.7671\nEpoch 64/500\n3304/3304 [==============================] - 13s 4ms/step - loss: 1.0236 - accuracy: 0.7665 - val_loss: 1.0151 - val_accuracy: 0.7671\nEpoch 65/500\n3304/3304 [==============================] - 13s 4ms/step - loss: 1.0235 - accuracy: 0.7665 - val_loss: 1.0150 - val_accuracy: 0.7671\nEpoch 66/500\n3304/3304 [==============================] - 13s 4ms/step - loss: 1.0233 - accuracy: 0.7665 - val_loss: 1.0149 - val_accuracy: 0.7671\nEpoch 67/500\n3304/3304 [==============================] - 13s 4ms/step - loss: 1.0231 - accuracy: 0.7665 - val_loss: 1.0148 - val_accuracy: 0.7671\nEpoch 68/500\n3304/3304 [==============================] - 13s 4ms/step - loss: 1.0229 - accuracy: 0.7666 - val_loss: 1.0147 - val_accuracy: 0.7671\nEpoch 69/500\n3304/3304 [==============================] - 13s 4ms/step - loss: 1.0227 - accuracy: 0.7666 - val_loss: 1.0146 - val_accuracy: 0.7670\nEpoch 70/500\n3304/3304 [==============================] - 13s 4ms/step - loss: 1.0226 - accuracy: 0.7666 - val_loss: 1.0145 - val_accuracy: 0.7671\nEpoch 71/500\n3304/3304 [==============================] - 13s 4ms/step - loss: 1.0224 - accuracy: 0.7666 - val_loss: 1.0144 - val_accuracy: 0.7671\nEpoch 72/500\n3304/3304 [==============================] - 13s 4ms/step - loss: 1.0222 - accuracy: 0.7666 - val_loss: 1.0143 - val_accuracy: 0.7671\nEpoch 73/500\n3304/3304 [==============================] - 12s 4ms/step - loss: 1.0220 - accuracy: 0.7666 - val_loss: 1.0142 - val_accuracy: 0.7671\nEpoch 74/500\n3304/3304 [==============================] - 13s 4ms/step - loss: 1.0219 - accuracy: 0.7666 - val_loss: 1.0141 - val_accuracy: 0.7671\nEpoch 75/500\n3304/3304 [==============================] - 13s 4ms/step - loss: 1.0217 - accuracy: 0.7666 - val_loss: 1.0141 - val_accuracy: 0.7671\nEpoch 76/500\n3304/3304 [==============================] - 13s 4ms/step - loss: 1.0215 - accuracy: 0.7667 - val_loss: 1.0140 - val_accuracy: 0.7671\nEpoch 77/500\n3304/3304 [==============================] - 13s 4ms/step - loss: 1.0214 - accuracy: 0.7667 - val_loss: 1.0139 - val_accuracy: 0.7671\nEpoch 78/500\n3304/3304 [==============================] - 12s 4ms/step - loss: 1.0212 - accuracy: 0.7667 - val_loss: 1.0138 - val_accuracy: 0.7671\nEpoch 79/500\n3304/3304 [==============================] - 13s 4ms/step - loss: 1.0210 - accuracy: 0.7667 - val_loss: 1.0137 - val_accuracy: 0.7671\nEpoch 80/500\n3304/3304 [==============================] - 13s 4ms/step - loss: 1.0208 - accuracy: 0.7667 - val_loss: 1.0136 - val_accuracy: 0.7672\nEpoch 81/500\n3304/3304 [==============================] - 13s 4ms/step - loss: 1.0207 - accuracy: 0.7667 - val_loss: 1.0135 - val_accuracy: 0.7672\nEpoch 82/500\n3304/3304 [==============================] - 13s 4ms/step - loss: 1.0205 - accuracy: 0.7668 - val_loss: 1.0134 - val_accuracy: 0.7672\nEpoch 83/500\n3304/3304 [==============================] - 13s 4ms/step - loss: 1.0203 - accuracy: 0.7668 - val_loss: 1.0133 - val_accuracy: 0.7672\nEpoch 84/500\n3304/3304 [==============================] - 13s 4ms/step - loss: 1.0202 - accuracy: 0.7668 - val_loss: 1.0132 - val_accuracy: 0.7672\nEpoch 85/500\n3304/3304 [==============================] - 13s 4ms/step - loss: 1.0200 - accuracy: 0.7668 - val_loss: 1.0131 - val_accuracy: 0.7672\nEpoch 86/500\n3304/3304 [==============================] - 13s 4ms/step - loss: 1.0198 - accuracy: 0.7668 - val_loss: 1.0130 - val_accuracy: 0.7671\nEpoch 87/500\n3304/3304 [==============================] - 13s 4ms/step - loss: 1.0197 - accuracy: 0.7668 - val_loss: 1.0130 - val_accuracy: 0.7671\nEpoch 88/500\n3304/3304 [==============================] - 13s 4ms/step - loss: 1.0195 - accuracy: 0.7669 - val_loss: 1.0129 - val_accuracy: 0.7671\nEpoch 89/500\n3304/3304 [==============================] - 13s 4ms/step - loss: 1.0193 - accuracy: 0.7668 - val_loss: 1.0128 - val_accuracy: 0.7672\nEpoch 90/500\n3304/3304 [==============================] - 13s 4ms/step - loss: 1.0192 - accuracy: 0.7669 - val_loss: 1.0127 - val_accuracy: 0.7672\nEpoch 91/500\n3304/3304 [==============================] - 13s 4ms/step - loss: 1.0190 - accuracy: 0.7669 - val_loss: 1.0126 - val_accuracy: 0.7672\nEpoch 92/500\n3304/3304 [==============================] - 13s 4ms/step - loss: 1.0189 - accuracy: 0.7669 - val_loss: 1.0125 - val_accuracy: 0.7672\nEpoch 93/500\n3304/3304 [==============================] - 13s 4ms/step - loss: 1.0187 - accuracy: 0.7669 - val_loss: 1.0124 - val_accuracy: 0.7672\nEpoch 94/500\n3304/3304 [==============================] - 13s 4ms/step - loss: 1.0185 - accuracy: 0.7669 - val_loss: 1.0124 - val_accuracy: 0.7671\nEpoch 95/500\n3304/3304 [==============================] - 13s 4ms/step - loss: 1.0184 - accuracy: 0.7669 - val_loss: 1.0123 - val_accuracy: 0.7671\nEpoch 96/500\n3304/3304 [==============================] - 13s 4ms/step - loss: 1.0182 - accuracy: 0.7669 - val_loss: 1.0122 - val_accuracy: 0.7671\nEpoch 97/500\n3304/3304 [==============================] - 13s 4ms/step - loss: 1.0181 - accuracy: 0.7670 - val_loss: 1.0121 - val_accuracy: 0.7671\nEpoch 98/500\n3304/3304 [==============================] - 13s 4ms/step - loss: 1.0179 - accuracy: 0.7670 - val_loss: 1.0120 - val_accuracy: 0.7671\nEpoch 99/500\n3304/3304 [==============================] - 13s 4ms/step - loss: 1.0177 - accuracy: 0.7670 - val_loss: 1.0119 - val_accuracy: 0.7671\nEpoch 100/500\n3304/3304 [==============================] - 13s 4ms/step - loss: 1.0176 - accuracy: 0.7670 - val_loss: 1.0119 - val_accuracy: 0.7671\nEpoch 101/500\n3304/3304 [==============================] - 13s 4ms/step - loss: 1.0174 - accuracy: 0.7670 - val_loss: 1.0118 - val_accuracy: 0.7671\nEpoch 102/500\n3304/3304 [==============================] - 13s 4ms/step - loss: 1.0173 - accuracy: 0.7670 - val_loss: 1.0117 - val_accuracy: 0.7672\nEpoch 103/500\n3304/3304 [==============================] - 13s 4ms/step - loss: 1.0171 - accuracy: 0.7670 - val_loss: 1.0116 - val_accuracy: 0.7671\nEpoch 104/500\n3304/3304 [==============================] - 13s 4ms/step - loss: 1.0170 - accuracy: 0.7671 - val_loss: 1.0115 - val_accuracy: 0.7672\nEpoch 105/500\n3304/3304 [==============================] - 13s 4ms/step - loss: 1.0168 - accuracy: 0.7671 - val_loss: 1.0114 - val_accuracy: 0.7672\nEpoch 106/500\n3304/3304 [==============================] - 13s 4ms/step - loss: 1.0167 - accuracy: 0.7671 - val_loss: 1.0114 - val_accuracy: 0.7672\nEpoch 107/500\n3304/3304 [==============================] - 13s 4ms/step - loss: 1.0165 - accuracy: 0.7671 - val_loss: 1.0113 - val_accuracy: 0.7672\nEpoch 108/500\n3304/3304 [==============================] - 13s 4ms/step - loss: 1.0163 - accuracy: 0.7671 - val_loss: 1.0112 - val_accuracy: 0.7672\nEpoch 109/500\n3304/3304 [==============================] - 13s 4ms/step - loss: 1.0162 - accuracy: 0.7671 - val_loss: 1.0111 - val_accuracy: 0.7672\nEpoch 110/500\n3304/3304 [==============================] - 13s 4ms/step - loss: 1.0160 - accuracy: 0.7672 - val_loss: 1.0110 - val_accuracy: 0.7672\nEpoch 111/500\n3304/3304 [==============================] - 13s 4ms/step - loss: 1.0159 - accuracy: 0.7672 - val_loss: 1.0110 - val_accuracy: 0.7672\nEpoch 112/500\n3304/3304 [==============================] - 13s 4ms/step - loss: 1.0157 - accuracy: 0.7672 - val_loss: 1.0109 - val_accuracy: 0.7672\nEpoch 113/500\n3304/3304 [==============================] - 13s 4ms/step - loss: 1.0156 - accuracy: 0.7672 - val_loss: 1.0108 - val_accuracy: 0.7672\nEpoch 114/500\n3304/3304 [==============================] - 13s 4ms/step - loss: 1.0154 - accuracy: 0.7672 - val_loss: 1.0107 - val_accuracy: 0.7672\nEpoch 115/500\n3304/3304 [==============================] - 13s 4ms/step - loss: 1.0153 - accuracy: 0.7673 - val_loss: 1.0107 - val_accuracy: 0.7672\nEpoch 116/500\n3304/3304 [==============================] - 14s 4ms/step - loss: 1.0151 - accuracy: 0.7673 - val_loss: 1.0106 - val_accuracy: 0.7672\nEpoch 117/500\n3304/3304 [==============================] - 13s 4ms/step - loss: 1.0150 - accuracy: 0.7673 - val_loss: 1.0105 - val_accuracy: 0.7672\nEpoch 118/500\n3304/3304 [==============================] - 13s 4ms/step - loss: 1.0148 - accuracy: 0.7673 - val_loss: 1.0104 - val_accuracy: 0.7672\nEpoch 119/500\n3304/3304 [==============================] - 13s 4ms/step - loss: 1.0147 - accuracy: 0.7673 - val_loss: 1.0104 - val_accuracy: 0.7672\nEpoch 120/500\n3304/3304 [==============================] - 13s 4ms/step - loss: 1.0145 - accuracy: 0.7673 - val_loss: 1.0103 - val_accuracy: 0.7673\nEpoch 121/500\n3304/3304 [==============================] - 13s 4ms/step - loss: 1.0144 - accuracy: 0.7674 - val_loss: 1.0102 - val_accuracy: 0.7673\nEpoch 122/500\n3304/3304 [==============================] - 13s 4ms/step - loss: 1.0142 - accuracy: 0.7674 - val_loss: 1.0101 - val_accuracy: 0.7673\nEpoch 123/500\n3304/3304 [==============================] - 13s 4ms/step - loss: 1.0141 - accuracy: 0.7674 - val_loss: 1.0101 - val_accuracy: 0.7673\nEpoch 124/500\n3304/3304 [==============================] - 13s 4ms/step - loss: 1.0140 - accuracy: 0.7674 - val_loss: 1.0100 - val_accuracy: 0.7672\nEpoch 125/500\n3304/3304 [==============================] - 13s 4ms/step - loss: 1.0138 - accuracy: 0.7674 - val_loss: 1.0099 - val_accuracy: 0.7673\nEpoch 126/500\n3304/3304 [==============================] - 13s 4ms/step - loss: 1.0137 - accuracy: 0.7675 - val_loss: 1.0098 - val_accuracy: 0.7673\nEpoch 127/500\n3304/3304 [==============================] - 13s 4ms/step - loss: 1.0135 - accuracy: 0.7675 - val_loss: 1.0098 - val_accuracy: 0.7673\nEpoch 128/500\n3304/3304 [==============================] - 13s 4ms/step - loss: 1.0134 - accuracy: 0.7675 - val_loss: 1.0097 - val_accuracy: 0.7673\nEpoch 129/500\n3304/3304 [==============================] - 13s 4ms/step - loss: 1.0132 - accuracy: 0.7675 - val_loss: 1.0096 - val_accuracy: 0.7673\nEpoch 130/500\n3304/3304 [==============================] - 13s 4ms/step - loss: 1.0131 - accuracy: 0.7675 - val_loss: 1.0096 - val_accuracy: 0.7673\nEpoch 131/500\n3304/3304 [==============================] - 13s 4ms/step - loss: 1.0129 - accuracy: 0.7675 - val_loss: 1.0095 - val_accuracy: 0.7673\nEpoch 132/500\n3304/3304 [==============================] - 13s 4ms/step - loss: 1.0128 - accuracy: 0.7675 - val_loss: 1.0094 - val_accuracy: 0.7673\nEpoch 133/500\n3304/3304 [==============================] - 13s 4ms/step - loss: 1.0127 - accuracy: 0.7675 - val_loss: 1.0094 - val_accuracy: 0.7673\nEpoch 134/500\n3304/3304 [==============================] - 13s 4ms/step - loss: 1.0125 - accuracy: 0.7676 - val_loss: 1.0093 - val_accuracy: 0.7673\nEpoch 135/500\n3304/3304 [==============================] - 13s 4ms/step - loss: 1.0124 - accuracy: 0.7676 - val_loss: 1.0092 - val_accuracy: 0.7673\nEpoch 136/500\n3304/3304 [==============================] - 13s 4ms/step - loss: 1.0122 - accuracy: 0.7676 - val_loss: 1.0091 - val_accuracy: 0.7673\nEpoch 137/500\n3304/3304 [==============================] - 13s 4ms/step - loss: 1.0121 - accuracy: 0.7676 - val_loss: 1.0091 - val_accuracy: 0.7673\nEpoch 138/500\n3304/3304 [==============================] - 13s 4ms/step - loss: 1.0120 - accuracy: 0.7676 - val_loss: 1.0090 - val_accuracy: 0.7673\nEpoch 139/500\n3304/3304 [==============================] - 13s 4ms/step - loss: 1.0118 - accuracy: 0.7677 - val_loss: 1.0089 - val_accuracy: 0.7673\nEpoch 140/500\n3304/3304 [==============================] - 13s 4ms/step - loss: 1.0117 - accuracy: 0.7677 - val_loss: 1.0089 - val_accuracy: 0.7673\nEpoch 141/500\n3304/3304 [==============================] - 13s 4ms/step - loss: 1.0115 - accuracy: 0.7677 - val_loss: 1.0088 - val_accuracy: 0.7673\nEpoch 142/500\n3304/3304 [==============================] - 13s 4ms/step - loss: 1.0114 - accuracy: 0.7677 - val_loss: 1.0087 - val_accuracy: 0.7674\nEpoch 143/500\n3304/3304 [==============================] - 13s 4ms/step - loss: 1.0113 - accuracy: 0.7678 - val_loss: 1.0087 - val_accuracy: 0.7674\nEpoch 144/500\n3304/3304 [==============================] - 13s 4ms/step - loss: 1.0111 - accuracy: 0.7678 - val_loss: 1.0086 - val_accuracy: 0.7674\nEpoch 145/500\n3304/3304 [==============================] - 13s 4ms/step - loss: 1.0110 - accuracy: 0.7678 - val_loss: 1.0085 - val_accuracy: 0.7674\nEpoch 146/500\n3304/3304 [==============================] - 13s 4ms/step - loss: 1.0108 - accuracy: 0.7678 - val_loss: 1.0085 - val_accuracy: 0.7674\nEpoch 147/500\n3304/3304 [==============================] - 13s 4ms/step - loss: 1.0107 - accuracy: 0.7678 - val_loss: 1.0084 - val_accuracy: 0.7674\nEpoch 148/500\n3304/3304 [==============================] - 12s 4ms/step - loss: 1.0106 - accuracy: 0.7678 - val_loss: 1.0083 - val_accuracy: 0.7674\nEpoch 149/500\n3304/3304 [==============================] - 13s 4ms/step - loss: 1.0104 - accuracy: 0.7678 - val_loss: 1.0083 - val_accuracy: 0.7674\nEpoch 150/500\n3304/3304 [==============================] - 13s 4ms/step - loss: 1.0103 - accuracy: 0.7678 - val_loss: 1.0082 - val_accuracy: 0.7674\nEpoch 151/500\n3304/3304 [==============================] - 13s 4ms/step - loss: 1.0102 - accuracy: 0.7678 - val_loss: 1.0081 - val_accuracy: 0.7675\nEpoch 152/500\n3304/3304 [==============================] - 13s 4ms/step - loss: 1.0100 - accuracy: 0.7678 - val_loss: 1.0081 - val_accuracy: 0.7675\nEpoch 153/500\n3304/3304 [==============================] - 13s 4ms/step - loss: 1.0099 - accuracy: 0.7679 - val_loss: 1.0080 - val_accuracy: 0.7675\nEpoch 154/500\n3304/3304 [==============================] - 13s 4ms/step - loss: 1.0098 - accuracy: 0.7679 - val_loss: 1.0080 - val_accuracy: 0.7675\nEpoch 155/500\n3304/3304 [==============================] - 13s 4ms/step - loss: 1.0096 - accuracy: 0.7679 - val_loss: 1.0079 - val_accuracy: 0.7675\nEpoch 156/500\n3304/3304 [==============================] - 13s 4ms/step - loss: 1.0095 - accuracy: 0.7679 - val_loss: 1.0078 - val_accuracy: 0.7674\nEpoch 157/500\n3304/3304 [==============================] - 13s 4ms/step - loss: 1.0094 - accuracy: 0.7679 - val_loss: 1.0078 - val_accuracy: 0.7674\nEpoch 158/500\n3304/3304 [==============================] - 12s 4ms/step - loss: 1.0092 - accuracy: 0.7679 - val_loss: 1.0077 - val_accuracy: 0.7675\nEpoch 159/500\n3304/3304 [==============================] - 13s 4ms/step - loss: 1.0091 - accuracy: 0.7680 - val_loss: 1.0076 - val_accuracy: 0.7675\nEpoch 160/500\n3304/3304 [==============================] - 13s 4ms/step - loss: 1.0090 - accuracy: 0.7680 - val_loss: 1.0076 - val_accuracy: 0.7675\nEpoch 161/500\n3304/3304 [==============================] - 13s 4ms/step - loss: 1.0088 - accuracy: 0.7680 - val_loss: 1.0075 - val_accuracy: 0.7675\nEpoch 162/500\n3304/3304 [==============================] - 13s 4ms/step - loss: 1.0087 - accuracy: 0.7680 - val_loss: 1.0075 - val_accuracy: 0.7675\nEpoch 163/500\n3304/3304 [==============================] - 13s 4ms/step - loss: 1.0086 - accuracy: 0.7680 - val_loss: 1.0074 - val_accuracy: 0.7675\nEpoch 164/500\n3304/3304 [==============================] - 13s 4ms/step - loss: 1.0084 - accuracy: 0.7680 - val_loss: 1.0073 - val_accuracy: 0.7675\nEpoch 165/500\n3304/3304 [==============================] - 13s 4ms/step - loss: 1.0083 - accuracy: 0.7680 - val_loss: 1.0073 - val_accuracy: 0.7675\nEpoch 166/500\n3304/3304 [==============================] - 13s 4ms/step - loss: 1.0082 - accuracy: 0.7680 - val_loss: 1.0072 - val_accuracy: 0.7675\nEpoch 167/500\n3304/3304 [==============================] - 13s 4ms/step - loss: 1.0080 - accuracy: 0.7680 - val_loss: 1.0072 - val_accuracy: 0.7675\nEpoch 168/500\n3304/3304 [==============================] - 13s 4ms/step - loss: 1.0079 - accuracy: 0.7680 - val_loss: 1.0071 - val_accuracy: 0.7675\nEpoch 169/500\n3304/3304 [==============================] - 13s 4ms/step - loss: 1.0078 - accuracy: 0.7681 - val_loss: 1.0070 - val_accuracy: 0.7675\nEpoch 170/500\n3304/3304 [==============================] - 13s 4ms/step - loss: 1.0076 - accuracy: 0.7681 - val_loss: 1.0070 - val_accuracy: 0.7675\nEpoch 171/500\n3304/3304 [==============================] - 13s 4ms/step - loss: 1.0075 - accuracy: 0.7681 - val_loss: 1.0069 - val_accuracy: 0.7675\nEpoch 172/500\n3304/3304 [==============================] - 13s 4ms/step - loss: 1.0074 - accuracy: 0.7682 - val_loss: 1.0069 - val_accuracy: 0.7675\nEpoch 173/500\n3304/3304 [==============================] - 13s 4ms/step - loss: 1.0073 - accuracy: 0.7682 - val_loss: 1.0068 - val_accuracy: 0.7675\nEpoch 174/500\n3304/3304 [==============================] - 13s 4ms/step - loss: 1.0071 - accuracy: 0.7682 - val_loss: 1.0067 - val_accuracy: 0.7675\nEpoch 175/500\n3304/3304 [==============================] - 13s 4ms/step - loss: 1.0070 - accuracy: 0.7682 - val_loss: 1.0067 - val_accuracy: 0.7675\nEpoch 176/500\n3304/3304 [==============================] - 12s 4ms/step - loss: 1.0069 - accuracy: 0.7682 - val_loss: 1.0066 - val_accuracy: 0.7675\nEpoch 177/500\n3304/3304 [==============================] - 13s 4ms/step - loss: 1.0068 - accuracy: 0.7682 - val_loss: 1.0066 - val_accuracy: 0.7675\nEpoch 178/500\n3304/3304 [==============================] - 13s 4ms/step - loss: 1.0066 - accuracy: 0.7682 - val_loss: 1.0065 - val_accuracy: 0.7675\nEpoch 179/500\n3304/3304 [==============================] - 13s 4ms/step - loss: 1.0065 - accuracy: 0.7683 - val_loss: 1.0065 - val_accuracy: 0.7675\nEpoch 180/500\n3304/3304 [==============================] - 13s 4ms/step - loss: 1.0064 - accuracy: 0.7683 - val_loss: 1.0064 - val_accuracy: 0.7675\nEpoch 181/500\n3304/3304 [==============================] - 13s 4ms/step - loss: 1.0062 - accuracy: 0.7683 - val_loss: 1.0063 - val_accuracy: 0.7675\nEpoch 182/500\n3304/3304 [==============================] - 13s 4ms/step - loss: 1.0061 - accuracy: 0.7683 - val_loss: 1.0063 - val_accuracy: 0.7676\nEpoch 183/500\n3304/3304 [==============================] - 14s 4ms/step - loss: 1.0060 - accuracy: 0.7683 - val_loss: 1.0062 - val_accuracy: 0.7676\nEpoch 184/500\n3304/3304 [==============================] - 13s 4ms/step - loss: 1.0059 - accuracy: 0.7683 - val_loss: 1.0062 - val_accuracy: 0.7676\nEpoch 185/500\n3304/3304 [==============================] - 13s 4ms/step - loss: 1.0057 - accuracy: 0.7683 - val_loss: 1.0061 - val_accuracy: 0.7676\nEpoch 186/500\n3304/3304 [==============================] - 13s 4ms/step - loss: 1.0056 - accuracy: 0.7684 - val_loss: 1.0061 - val_accuracy: 0.7676\nEpoch 187/500\n3304/3304 [==============================] - 13s 4ms/step - loss: 1.0055 - accuracy: 0.7684 - val_loss: 1.0060 - val_accuracy: 0.7676\nEpoch 188/500\n3304/3304 [==============================] - 13s 4ms/step - loss: 1.0054 - accuracy: 0.7684 - val_loss: 1.0059 - val_accuracy: 0.7676\nEpoch 189/500\n3304/3304 [==============================] - 13s 4ms/step - loss: 1.0052 - accuracy: 0.7684 - val_loss: 1.0059 - val_accuracy: 0.7676\nEpoch 190/500\n3304/3304 [==============================] - 13s 4ms/step - loss: 1.0051 - accuracy: 0.7684 - val_loss: 1.0058 - val_accuracy: 0.7676\nEpoch 191/500\n3304/3304 [==============================] - 13s 4ms/step - loss: 1.0050 - accuracy: 0.7684 - val_loss: 1.0058 - val_accuracy: 0.7676\nEpoch 192/500\n3304/3304 [==============================] - 13s 4ms/step - loss: 1.0049 - accuracy: 0.7685 - val_loss: 1.0057 - val_accuracy: 0.7676\nEpoch 193/500\n3304/3304 [==============================] - 13s 4ms/step - loss: 1.0047 - accuracy: 0.7685 - val_loss: 1.0057 - val_accuracy: 0.7676\nEpoch 194/500\n3304/3304 [==============================] - 13s 4ms/step - loss: 1.0046 - accuracy: 0.7685 - val_loss: 1.0056 - val_accuracy: 0.7676\nEpoch 195/500\n3304/3304 [==============================] - 13s 4ms/step - loss: 1.0045 - accuracy: 0.7685 - val_loss: 1.0056 - val_accuracy: 0.7676\nEpoch 196/500\n3304/3304 [==============================] - 13s 4ms/step - loss: 1.0044 - accuracy: 0.7685 - val_loss: 1.0055 - val_accuracy: 0.7676\nEpoch 197/500\n3304/3304 [==============================] - 13s 4ms/step - loss: 1.0043 - accuracy: 0.7685 - val_loss: 1.0055 - val_accuracy: 0.7676\nEpoch 198/500\n3304/3304 [==============================] - 13s 4ms/step - loss: 1.0041 - accuracy: 0.7686 - val_loss: 1.0054 - val_accuracy: 0.7676\nEpoch 199/500\n3304/3304 [==============================] - 13s 4ms/step - loss: 1.0040 - accuracy: 0.7686 - val_loss: 1.0053 - val_accuracy: 0.7676\nEpoch 200/500\n3304/3304 [==============================] - 13s 4ms/step - loss: 1.0039 - accuracy: 0.7686 - val_loss: 1.0053 - val_accuracy: 0.7676\nEpoch 201/500\n3304/3304 [==============================] - 13s 4ms/step - loss: 1.0038 - accuracy: 0.7686 - val_loss: 1.0052 - val_accuracy: 0.7676\nEpoch 202/500\n3304/3304 [==============================] - 13s 4ms/step - loss: 1.0037 - accuracy: 0.7686 - val_loss: 1.0052 - val_accuracy: 0.7677\nEpoch 203/500\n3304/3304 [==============================] - 13s 4ms/step - loss: 1.0035 - accuracy: 0.7686 - val_loss: 1.0051 - val_accuracy: 0.7676\nEpoch 204/500\n3304/3304 [==============================] - 13s 4ms/step - loss: 1.0034 - accuracy: 0.7687 - val_loss: 1.0051 - val_accuracy: 0.7676\nEpoch 205/500\n3304/3304 [==============================] - 13s 4ms/step - loss: 1.0033 - accuracy: 0.7687 - val_loss: 1.0050 - val_accuracy: 0.7676\nEpoch 206/500\n3304/3304 [==============================] - 14s 4ms/step - loss: 1.0032 - accuracy: 0.7687 - val_loss: 1.0050 - val_accuracy: 0.7676\nEpoch 207/500\n3304/3304 [==============================] - 13s 4ms/step - loss: 1.0031 - accuracy: 0.7687 - val_loss: 1.0049 - val_accuracy: 0.7676\nEpoch 208/500\n3304/3304 [==============================] - 13s 4ms/step - loss: 1.0029 - accuracy: 0.7688 - val_loss: 1.0049 - val_accuracy: 0.7676\nEpoch 209/500\n3304/3304 [==============================] - 13s 4ms/step - loss: 1.0028 - accuracy: 0.7688 - val_loss: 1.0048 - val_accuracy: 0.7676\nEpoch 210/500\n3304/3304 [==============================] - 13s 4ms/step - loss: 1.0027 - accuracy: 0.7688 - val_loss: 1.0048 - val_accuracy: 0.7676\nEpoch 211/500\n3304/3304 [==============================] - 13s 4ms/step - loss: 1.0026 - accuracy: 0.7688 - val_loss: 1.0047 - val_accuracy: 0.7677\nEpoch 212/500\n3304/3304 [==============================] - 13s 4ms/step - loss: 1.0025 - accuracy: 0.7688 - val_loss: 1.0047 - val_accuracy: 0.7677\nEpoch 213/500\n3304/3304 [==============================] - 13s 4ms/step - loss: 1.0023 - accuracy: 0.7688 - val_loss: 1.0046 - val_accuracy: 0.7677\nEpoch 214/500\n3304/3304 [==============================] - 13s 4ms/step - loss: 1.0022 - accuracy: 0.7688 - val_loss: 1.0046 - val_accuracy: 0.7676\nEpoch 215/500\n3304/3304 [==============================] - 13s 4ms/step - loss: 1.0021 - accuracy: 0.7688 - val_loss: 1.0045 - val_accuracy: 0.7676\nEpoch 216/500\n3304/3304 [==============================] - 12s 4ms/step - loss: 1.0020 - accuracy: 0.7688 - val_loss: 1.0045 - val_accuracy: 0.7676\nEpoch 217/500\n3304/3304 [==============================] - 13s 4ms/step - loss: 1.0019 - accuracy: 0.7688 - val_loss: 1.0044 - val_accuracy: 0.7676\nEpoch 218/500\n3304/3304 [==============================] - 13s 4ms/step - loss: 1.0018 - accuracy: 0.7688 - val_loss: 1.0044 - val_accuracy: 0.7676\nEpoch 219/500\n3304/3304 [==============================] - 13s 4ms/step - loss: 1.0016 - accuracy: 0.7689 - val_loss: 1.0043 - val_accuracy: 0.7676\nEpoch 220/500\n3304/3304 [==============================] - 13s 4ms/step - loss: 1.0015 - accuracy: 0.7689 - val_loss: 1.0043 - val_accuracy: 0.7676\nEpoch 221/500\n3304/3304 [==============================] - 13s 4ms/step - loss: 1.0014 - accuracy: 0.7689 - val_loss: 1.0042 - val_accuracy: 0.7676\nEpoch 222/500\n3304/3304 [==============================] - 13s 4ms/step - loss: 1.0013 - accuracy: 0.7689 - val_loss: 1.0042 - val_accuracy: 0.7676\nEpoch 223/500\n3304/3304 [==============================] - 13s 4ms/step - loss: 1.0012 - accuracy: 0.7689 - val_loss: 1.0041 - val_accuracy: 0.7676\nEpoch 224/500\n3304/3304 [==============================] - 13s 4ms/step - loss: 1.0011 - accuracy: 0.7690 - val_loss: 1.0041 - val_accuracy: 0.7676\nEpoch 225/500\n3304/3304 [==============================] - 13s 4ms/step - loss: 1.0009 - accuracy: 0.7690 - val_loss: 1.0040 - val_accuracy: 0.7677\nEpoch 226/500\n3304/3304 [==============================] - 13s 4ms/step - loss: 1.0008 - accuracy: 0.7690 - val_loss: 1.0040 - val_accuracy: 0.7677\nEpoch 227/500\n3304/3304 [==============================] - 13s 4ms/step - loss: 1.0007 - accuracy: 0.7690 - val_loss: 1.0039 - val_accuracy: 0.7677\nEpoch 228/500\n3304/3304 [==============================] - 13s 4ms/step - loss: 1.0006 - accuracy: 0.7690 - val_loss: 1.0039 - val_accuracy: 0.7677\nEpoch 229/500\n3304/3304 [==============================] - 13s 4ms/step - loss: 1.0005 - accuracy: 0.7690 - val_loss: 1.0038 - val_accuracy: 0.7677\nEpoch 230/500\n3304/3304 [==============================] - 13s 4ms/step - loss: 1.0004 - accuracy: 0.7691 - val_loss: 1.0038 - val_accuracy: 0.7677\nEpoch 231/500\n3304/3304 [==============================] - 13s 4ms/step - loss: 1.0003 - accuracy: 0.7691 - val_loss: 1.0038 - val_accuracy: 0.7677\nEpoch 232/500\n3304/3304 [==============================] - 13s 4ms/step - loss: 1.0001 - accuracy: 0.7691 - val_loss: 1.0037 - val_accuracy: 0.7677\nEpoch 233/500\n3304/3304 [==============================] - 14s 4ms/step - loss: 1.0000 - accuracy: 0.7691 - val_loss: 1.0037 - val_accuracy: 0.7677\nEpoch 234/500\n3304/3304 [==============================] - 13s 4ms/step - loss: 0.9999 - accuracy: 0.7691 - val_loss: 1.0036 - val_accuracy: 0.7677\nEpoch 235/500\n3304/3304 [==============================] - 13s 4ms/step - loss: 0.9998 - accuracy: 0.7691 - val_loss: 1.0036 - val_accuracy: 0.7677\nEpoch 236/500\n3304/3304 [==============================] - 13s 4ms/step - loss: 0.9997 - accuracy: 0.7691 - val_loss: 1.0035 - val_accuracy: 0.7678\nEpoch 237/500\n3304/3304 [==============================] - 13s 4ms/step - loss: 0.9996 - accuracy: 0.7692 - val_loss: 1.0035 - val_accuracy: 0.7678\nEpoch 238/500\n3304/3304 [==============================] - 13s 4ms/step - loss: 0.9995 - accuracy: 0.7692 - val_loss: 1.0034 - val_accuracy: 0.7678\nEpoch 239/500\n3304/3304 [==============================] - 13s 4ms/step - loss: 0.9994 - accuracy: 0.7692 - val_loss: 1.0034 - val_accuracy: 0.7677\nEpoch 240/500\n3304/3304 [==============================] - 13s 4ms/step - loss: 0.9992 - accuracy: 0.7692 - val_loss: 1.0033 - val_accuracy: 0.7678\nEpoch 241/500\n3304/3304 [==============================] - 14s 4ms/step - loss: 0.9991 - accuracy: 0.7692 - val_loss: 1.0033 - val_accuracy: 0.7678\nEpoch 242/500\n3304/3304 [==============================] - 13s 4ms/step - loss: 0.9990 - accuracy: 0.7692 - val_loss: 1.0032 - val_accuracy: 0.7678\nEpoch 243/500\n3304/3304 [==============================] - 13s 4ms/step - loss: 0.9989 - accuracy: 0.7692 - val_loss: 1.0032 - val_accuracy: 0.7677\nEpoch 244/500\n3304/3304 [==============================] - 13s 4ms/step - loss: 0.9988 - accuracy: 0.7693 - val_loss: 1.0032 - val_accuracy: 0.7677\nEpoch 245/500\n3304/3304 [==============================] - 12s 4ms/step - loss: 0.9987 - accuracy: 0.7693 - val_loss: 1.0031 - val_accuracy: 0.7677\nEpoch 246/500\n3304/3304 [==============================] - 13s 4ms/step - loss: 0.9986 - accuracy: 0.7693 - val_loss: 1.0031 - val_accuracy: 0.7677\nEpoch 247/500\n3304/3304 [==============================] - 14s 4ms/step - loss: 0.9985 - accuracy: 0.7693 - val_loss: 1.0030 - val_accuracy: 0.7678\nEpoch 248/500\n3304/3304 [==============================] - 13s 4ms/step - loss: 0.9983 - accuracy: 0.7693 - val_loss: 1.0030 - val_accuracy: 0.7677\nEpoch 249/500\n3304/3304 [==============================] - 13s 4ms/step - loss: 0.9982 - accuracy: 0.7693 - val_loss: 1.0029 - val_accuracy: 0.7678\nEpoch 250/500\n3304/3304 [==============================] - 13s 4ms/step - loss: 0.9981 - accuracy: 0.7693 - val_loss: 1.0029 - val_accuracy: 0.7677\nEpoch 251/500\n3304/3304 [==============================] - 13s 4ms/step - loss: 0.9980 - accuracy: 0.7693 - val_loss: 1.0028 - val_accuracy: 0.7678\nEpoch 252/500\n3304/3304 [==============================] - 13s 4ms/step - loss: 0.9979 - accuracy: 0.7694 - val_loss: 1.0028 - val_accuracy: 0.7677\nEpoch 253/500\n3304/3304 [==============================] - 13s 4ms/step - loss: 0.9978 - accuracy: 0.7694 - val_loss: 1.0028 - val_accuracy: 0.7677\nEpoch 254/500\n3304/3304 [==============================] - 13s 4ms/step - loss: 0.9977 - accuracy: 0.7694 - val_loss: 1.0027 - val_accuracy: 0.7678\nEpoch 255/500\n3304/3304 [==============================] - 13s 4ms/step - loss: 0.9976 - accuracy: 0.7694 - val_loss: 1.0027 - val_accuracy: 0.7678\nEpoch 256/500\n3304/3304 [==============================] - 13s 4ms/step - loss: 0.9975 - accuracy: 0.7694 - val_loss: 1.0026 - val_accuracy: 0.7678\nEpoch 257/500\n3304/3304 [==============================] - 14s 4ms/step - loss: 0.9974 - accuracy: 0.7694 - val_loss: 1.0026 - val_accuracy: 0.7678\nEpoch 258/500\n3304/3304 [==============================] - 13s 4ms/step - loss: 0.9972 - accuracy: 0.7694 - val_loss: 1.0025 - val_accuracy: 0.7678\nEpoch 259/500\n3304/3304 [==============================] - 13s 4ms/step - loss: 0.9971 - accuracy: 0.7695 - val_loss: 1.0025 - val_accuracy: 0.7678\nEpoch 260/500\n3304/3304 [==============================] - 13s 4ms/step - loss: 0.9970 - accuracy: 0.7695 - val_loss: 1.0025 - val_accuracy: 0.7678\nEpoch 261/500\n3304/3304 [==============================] - 13s 4ms/step - loss: 0.9969 - accuracy: 0.7695 - val_loss: 1.0024 - val_accuracy: 0.7678\nEpoch 262/500\n3304/3304 [==============================] - 13s 4ms/step - loss: 0.9968 - accuracy: 0.7695 - val_loss: 1.0024 - val_accuracy: 0.7679\nEpoch 263/500\n3304/3304 [==============================] - 13s 4ms/step - loss: 0.9967 - accuracy: 0.7695 - val_loss: 1.0023 - val_accuracy: 0.7678\nEpoch 264/500\n3304/3304 [==============================] - 13s 4ms/step - loss: 0.9966 - accuracy: 0.7695 - val_loss: 1.0023 - val_accuracy: 0.7678\nEpoch 265/500\n3304/3304 [==============================] - 13s 4ms/step - loss: 0.9965 - accuracy: 0.7695 - val_loss: 1.0022 - val_accuracy: 0.7679\nEpoch 266/500\n3304/3304 [==============================] - 13s 4ms/step - loss: 0.9964 - accuracy: 0.7696 - val_loss: 1.0022 - val_accuracy: 0.7679\nEpoch 267/500\n3304/3304 [==============================] - 13s 4ms/step - loss: 0.9963 - accuracy: 0.7696 - val_loss: 1.0022 - val_accuracy: 0.7679\nEpoch 268/500\n3304/3304 [==============================] - 13s 4ms/step - loss: 0.9962 - accuracy: 0.7696 - val_loss: 1.0021 - val_accuracy: 0.7679\nEpoch 269/500\n3304/3304 [==============================] - 13s 4ms/step - loss: 0.9961 - accuracy: 0.7696 - val_loss: 1.0021 - val_accuracy: 0.7679\nEpoch 270/500\n3304/3304 [==============================] - 13s 4ms/step - loss: 0.9960 - accuracy: 0.7696 - val_loss: 1.0020 - val_accuracy: 0.7679\nEpoch 271/500\n3304/3304 [==============================] - 13s 4ms/step - loss: 0.9958 - accuracy: 0.7697 - val_loss: 1.0020 - val_accuracy: 0.7679\nEpoch 272/500\n3304/3304 [==============================] - 13s 4ms/step - loss: 0.9957 - accuracy: 0.7697 - val_loss: 1.0019 - val_accuracy: 0.7679\nEpoch 273/500\n3304/3304 [==============================] - 13s 4ms/step - loss: 0.9956 - accuracy: 0.7697 - val_loss: 1.0019 - val_accuracy: 0.7679\nEpoch 274/500\n3304/3304 [==============================] - 13s 4ms/step - loss: 0.9955 - accuracy: 0.7697 - val_loss: 1.0019 - val_accuracy: 0.7679\nEpoch 275/500\n3304/3304 [==============================] - 14s 4ms/step - loss: 0.9954 - accuracy: 0.7697 - val_loss: 1.0018 - val_accuracy: 0.7679\nEpoch 276/500\n3304/3304 [==============================] - 13s 4ms/step - loss: 0.9953 - accuracy: 0.7697 - val_loss: 1.0018 - val_accuracy: 0.7679\nEpoch 277/500\n3304/3304 [==============================] - 13s 4ms/step - loss: 0.9952 - accuracy: 0.7697 - val_loss: 1.0017 - val_accuracy: 0.7679\nEpoch 278/500\n3304/3304 [==============================] - 13s 4ms/step - loss: 0.9951 - accuracy: 0.7697 - val_loss: 1.0017 - val_accuracy: 0.7679\nEpoch 279/500\n3304/3304 [==============================] - 13s 4ms/step - loss: 0.9950 - accuracy: 0.7698 - val_loss: 1.0017 - val_accuracy: 0.7679\nEpoch 280/500\n3304/3304 [==============================] - 14s 4ms/step - loss: 0.9949 - accuracy: 0.7698 - val_loss: 1.0016 - val_accuracy: 0.7679\nEpoch 281/500\n3304/3304 [==============================] - 13s 4ms/step - loss: 0.9948 - accuracy: 0.7698 - val_loss: 1.0016 - val_accuracy: 0.7679\nEpoch 282/500\n3304/3304 [==============================] - 13s 4ms/step - loss: 0.9947 - accuracy: 0.7698 - val_loss: 1.0015 - val_accuracy: 0.7679\nEpoch 283/500\n3304/3304 [==============================] - 13s 4ms/step - loss: 0.9946 - accuracy: 0.7698 - val_loss: 1.0015 - val_accuracy: 0.7679\nEpoch 284/500\n3304/3304 [==============================] - 13s 4ms/step - loss: 0.9945 - accuracy: 0.7698 - val_loss: 1.0015 - val_accuracy: 0.7679\nEpoch 285/500\n3304/3304 [==============================] - 13s 4ms/step - loss: 0.9944 - accuracy: 0.7698 - val_loss: 1.0014 - val_accuracy: 0.7679\nEpoch 286/500\n3304/3304 [==============================] - 13s 4ms/step - loss: 0.9943 - accuracy: 0.7698 - val_loss: 1.0014 - val_accuracy: 0.7679\nEpoch 287/500\n3304/3304 [==============================] - 13s 4ms/step - loss: 0.9942 - accuracy: 0.7699 - val_loss: 1.0013 - val_accuracy: 0.7679\nEpoch 288/500\n3304/3304 [==============================] - 13s 4ms/step - loss: 0.9941 - accuracy: 0.7699 - val_loss: 1.0013 - val_accuracy: 0.7679\nEpoch 289/500\n3304/3304 [==============================] - 13s 4ms/step - loss: 0.9940 - accuracy: 0.7699 - val_loss: 1.0013 - val_accuracy: 0.7679\nEpoch 290/500\n3304/3304 [==============================] - 13s 4ms/step - loss: 0.9938 - accuracy: 0.7699 - val_loss: 1.0012 - val_accuracy: 0.7679\nEpoch 291/500\n3304/3304 [==============================] - 13s 4ms/step - loss: 0.9937 - accuracy: 0.7699 - val_loss: 1.0012 - val_accuracy: 0.7679\nEpoch 292/500\n3304/3304 [==============================] - 13s 4ms/step - loss: 0.9936 - accuracy: 0.7700 - val_loss: 1.0011 - val_accuracy: 0.7679\nEpoch 293/500\n3304/3304 [==============================] - 13s 4ms/step - loss: 0.9935 - accuracy: 0.7700 - val_loss: 1.0011 - val_accuracy: 0.7679\nEpoch 294/500\n3304/3304 [==============================] - 13s 4ms/step - loss: 0.9934 - accuracy: 0.7700 - val_loss: 1.0011 - val_accuracy: 0.7679\nEpoch 295/500\n3304/3304 [==============================] - 13s 4ms/step - loss: 0.9933 - accuracy: 0.7700 - val_loss: 1.0010 - val_accuracy: 0.7679\nEpoch 296/500\n3304/3304 [==============================] - 13s 4ms/step - loss: 0.9932 - accuracy: 0.7700 - val_loss: 1.0010 - val_accuracy: 0.7679\nEpoch 297/500\n3304/3304 [==============================] - 13s 4ms/step - loss: 0.9931 - accuracy: 0.7700 - val_loss: 1.0009 - val_accuracy: 0.7680\nEpoch 298/500\n3304/3304 [==============================] - 13s 4ms/step - loss: 0.9930 - accuracy: 0.7700 - val_loss: 1.0009 - val_accuracy: 0.7679\nEpoch 299/500\n3304/3304 [==============================] - 13s 4ms/step - loss: 0.9929 - accuracy: 0.7701 - val_loss: 1.0009 - val_accuracy: 0.7679\nEpoch 300/500\n3304/3304 [==============================] - 13s 4ms/step - loss: 0.9928 - accuracy: 0.7701 - val_loss: 1.0008 - val_accuracy: 0.7680\nEpoch 301/500\n3304/3304 [==============================] - 13s 4ms/step - loss: 0.9927 - accuracy: 0.7701 - val_loss: 1.0008 - val_accuracy: 0.7680\nEpoch 302/500\n3304/3304 [==============================] - 13s 4ms/step - loss: 0.9926 - accuracy: 0.7701 - val_loss: 1.0008 - val_accuracy: 0.7680\nEpoch 303/500\n3304/3304 [==============================] - 13s 4ms/step - loss: 0.9925 - accuracy: 0.7701 - val_loss: 1.0007 - val_accuracy: 0.7680\nEpoch 304/500\n3304/3304 [==============================] - 13s 4ms/step - loss: 0.9924 - accuracy: 0.7701 - val_loss: 1.0007 - val_accuracy: 0.7680\nEpoch 305/500\n3304/3304 [==============================] - 13s 4ms/step - loss: 0.9923 - accuracy: 0.7702 - val_loss: 1.0006 - val_accuracy: 0.7680\nEpoch 306/500\n3304/3304 [==============================] - 13s 4ms/step - loss: 0.9922 - accuracy: 0.7702 - val_loss: 1.0006 - val_accuracy: 0.7680\nEpoch 307/500\n3304/3304 [==============================] - 13s 4ms/step - loss: 0.9921 - accuracy: 0.7702 - val_loss: 1.0006 - val_accuracy: 0.7680\nEpoch 308/500\n3304/3304 [==============================] - 13s 4ms/step - loss: 0.9920 - accuracy: 0.7702 - val_loss: 1.0005 - val_accuracy: 0.7680\nEpoch 309/500\n3304/3304 [==============================] - 13s 4ms/step - loss: 0.9919 - accuracy: 0.7702 - val_loss: 1.0005 - val_accuracy: 0.7680\nEpoch 310/500\n3304/3304 [==============================] - 13s 4ms/step - loss: 0.9918 - accuracy: 0.7702 - val_loss: 1.0005 - val_accuracy: 0.7680\nEpoch 311/500\n3304/3304 [==============================] - 13s 4ms/step - loss: 0.9917 - accuracy: 0.7703 - val_loss: 1.0004 - val_accuracy: 0.7681\nEpoch 312/500\n3304/3304 [==============================] - 13s 4ms/step - loss: 0.9916 - accuracy: 0.7703 - val_loss: 1.0004 - val_accuracy: 0.7681\nEpoch 313/500\n3304/3304 [==============================] - 13s 4ms/step - loss: 0.9915 - accuracy: 0.7703 - val_loss: 1.0003 - val_accuracy: 0.7681\nEpoch 314/500\n3304/3304 [==============================] - 13s 4ms/step - loss: 0.9914 - accuracy: 0.7703 - val_loss: 1.0003 - val_accuracy: 0.7681\nEpoch 315/500\n3304/3304 [==============================] - 13s 4ms/step - loss: 0.9913 - accuracy: 0.7703 - val_loss: 1.0003 - val_accuracy: 0.7681\nEpoch 316/500\n3304/3304 [==============================] - 13s 4ms/step - loss: 0.9912 - accuracy: 0.7703 - val_loss: 1.0002 - val_accuracy: 0.7681\nEpoch 317/500\n3304/3304 [==============================] - 13s 4ms/step - loss: 0.9911 - accuracy: 0.7703 - val_loss: 1.0002 - val_accuracy: 0.7681\nEpoch 318/500\n3304/3304 [==============================] - 12s 4ms/step - loss: 0.9910 - accuracy: 0.7703 - val_loss: 1.0002 - val_accuracy: 0.7681\nEpoch 319/500\n3304/3304 [==============================] - 13s 4ms/step - loss: 0.9909 - accuracy: 0.7704 - val_loss: 1.0001 - val_accuracy: 0.7681\nEpoch 320/500\n3304/3304 [==============================] - 13s 4ms/step - loss: 0.9908 - accuracy: 0.7704 - val_loss: 1.0001 - val_accuracy: 0.7681\nEpoch 321/500\n3304/3304 [==============================] - 13s 4ms/step - loss: 0.9907 - accuracy: 0.7704 - val_loss: 1.0001 - val_accuracy: 0.7681\nEpoch 322/500\n3304/3304 [==============================] - 13s 4ms/step - loss: 0.9906 - accuracy: 0.7704 - val_loss: 1.0000 - val_accuracy: 0.7681\nEpoch 323/500\n3304/3304 [==============================] - 13s 4ms/step - loss: 0.9905 - accuracy: 0.7704 - val_loss: 1.0000 - val_accuracy: 0.7681\nEpoch 324/500\n3304/3304 [==============================] - 13s 4ms/step - loss: 0.9904 - accuracy: 0.7704 - val_loss: 0.9999 - val_accuracy: 0.7681\nEpoch 325/500\n3304/3304 [==============================] - 13s 4ms/step - loss: 0.9903 - accuracy: 0.7704 - val_loss: 0.9999 - val_accuracy: 0.7681\nEpoch 326/500\n3304/3304 [==============================] - 13s 4ms/step - loss: 0.9902 - accuracy: 0.7704 - val_loss: 0.9999 - val_accuracy: 0.7681\nEpoch 327/500\n3304/3304 [==============================] - 13s 4ms/step - loss: 0.9901 - accuracy: 0.7705 - val_loss: 0.9998 - val_accuracy: 0.7681\nEpoch 328/500\n3304/3304 [==============================] - 13s 4ms/step - loss: 0.9900 - accuracy: 0.7705 - val_loss: 0.9998 - val_accuracy: 0.7681\nEpoch 329/500\n3304/3304 [==============================] - 13s 4ms/step - loss: 0.9899 - accuracy: 0.7705 - val_loss: 0.9998 - val_accuracy: 0.7681\nEpoch 330/500\n3304/3304 [==============================] - 13s 4ms/step - loss: 0.9898 - accuracy: 0.7705 - val_loss: 0.9997 - val_accuracy: 0.7681\nEpoch 331/500\n3304/3304 [==============================] - 13s 4ms/step - loss: 0.9897 - accuracy: 0.7705 - val_loss: 0.9997 - val_accuracy: 0.7681\nEpoch 332/500\n3304/3304 [==============================] - 13s 4ms/step - loss: 0.9896 - accuracy: 0.7705 - val_loss: 0.9997 - val_accuracy: 0.7681\nEpoch 333/500\n3304/3304 [==============================] - 13s 4ms/step - loss: 0.9895 - accuracy: 0.7705 - val_loss: 0.9996 - val_accuracy: 0.7681\nEpoch 334/500\n3304/3304 [==============================] - 13s 4ms/step - loss: 0.9894 - accuracy: 0.7705 - val_loss: 0.9996 - val_accuracy: 0.7681\nEpoch 335/500\n3304/3304 [==============================] - 13s 4ms/step - loss: 0.9893 - accuracy: 0.7706 - val_loss: 0.9996 - val_accuracy: 0.7681\nEpoch 336/500\n3304/3304 [==============================] - 14s 4ms/step - loss: 0.9892 - accuracy: 0.7706 - val_loss: 0.9995 - val_accuracy: 0.7681\nEpoch 337/500\n3304/3304 [==============================] - 13s 4ms/step - loss: 0.9891 - accuracy: 0.7706 - val_loss: 0.9995 - val_accuracy: 0.7681\nEpoch 338/500\n3304/3304 [==============================] - 13s 4ms/step - loss: 0.9890 - accuracy: 0.7706 - val_loss: 0.9995 - val_accuracy: 0.7681\nEpoch 339/500\n3304/3304 [==============================] - 13s 4ms/step - loss: 0.9889 - accuracy: 0.7706 - val_loss: 0.9994 - val_accuracy: 0.7681\nEpoch 340/500\n3304/3304 [==============================] - 13s 4ms/step - loss: 0.9888 - accuracy: 0.7706 - val_loss: 0.9994 - val_accuracy: 0.7681\nEpoch 341/500\n3304/3304 [==============================] - 13s 4ms/step - loss: 0.9887 - accuracy: 0.7707 - val_loss: 0.9994 - val_accuracy: 0.7681\nEpoch 342/500\n3304/3304 [==============================] - 13s 4ms/step - loss: 0.9886 - accuracy: 0.7707 - val_loss: 0.9993 - val_accuracy: 0.7681\nEpoch 343/500\n3304/3304 [==============================] - 13s 4ms/step - loss: 0.9885 - accuracy: 0.7707 - val_loss: 0.9993 - val_accuracy: 0.7681\nEpoch 344/500\n3304/3304 [==============================] - 13s 4ms/step - loss: 0.9884 - accuracy: 0.7707 - val_loss: 0.9993 - val_accuracy: 0.7681\nEpoch 345/500\n3304/3304 [==============================] - 13s 4ms/step - loss: 0.9883 - accuracy: 0.7707 - val_loss: 0.9992 - val_accuracy: 0.7681\nEpoch 346/500\n3304/3304 [==============================] - 13s 4ms/step - loss: 0.9882 - accuracy: 0.7707 - val_loss: 0.9992 - val_accuracy: 0.7681\nEpoch 347/500\n3304/3304 [==============================] - 13s 4ms/step - loss: 0.9882 - accuracy: 0.7707 - val_loss: 0.9991 - val_accuracy: 0.7681\nEpoch 348/500\n3304/3304 [==============================] - 13s 4ms/step - loss: 0.9881 - accuracy: 0.7708 - val_loss: 0.9991 - val_accuracy: 0.7681\nEpoch 349/500\n3304/3304 [==============================] - 13s 4ms/step - loss: 0.9880 - accuracy: 0.7708 - val_loss: 0.9991 - val_accuracy: 0.7681\nEpoch 350/500\n3304/3304 [==============================] - 13s 4ms/step - loss: 0.9879 - accuracy: 0.7708 - val_loss: 0.9990 - val_accuracy: 0.7682\nEpoch 351/500\n3304/3304 [==============================] - 13s 4ms/step - loss: 0.9878 - accuracy: 0.7708 - val_loss: 0.9990 - val_accuracy: 0.7682\nEpoch 352/500\n3304/3304 [==============================] - 13s 4ms/step - loss: 0.9877 - accuracy: 0.7709 - val_loss: 0.9990 - val_accuracy: 0.7682\nEpoch 353/500\n3304/3304 [==============================] - 13s 4ms/step - loss: 0.9876 - accuracy: 0.7709 - val_loss: 0.9989 - val_accuracy: 0.7682\nEpoch 354/500\n3304/3304 [==============================] - 13s 4ms/step - loss: 0.9875 - accuracy: 0.7709 - val_loss: 0.9989 - val_accuracy: 0.7682\nEpoch 355/500\n3304/3304 [==============================] - 13s 4ms/step - loss: 0.9874 - accuracy: 0.7709 - val_loss: 0.9989 - val_accuracy: 0.7682\nEpoch 356/500\n3304/3304 [==============================] - 13s 4ms/step - loss: 0.9873 - accuracy: 0.7709 - val_loss: 0.9988 - val_accuracy: 0.7682\nEpoch 357/500\n3304/3304 [==============================] - 13s 4ms/step - loss: 0.9872 - accuracy: 0.7709 - val_loss: 0.9988 - val_accuracy: 0.7682\nEpoch 358/500\n3304/3304 [==============================] - 13s 4ms/step - loss: 0.9871 - accuracy: 0.7709 - val_loss: 0.9988 - val_accuracy: 0.7682\nEpoch 359/500\n3304/3304 [==============================] - 13s 4ms/step - loss: 0.9870 - accuracy: 0.7709 - val_loss: 0.9987 - val_accuracy: 0.7682\nEpoch 360/500\n3304/3304 [==============================] - 13s 4ms/step - loss: 0.9869 - accuracy: 0.7709 - val_loss: 0.9987 - val_accuracy: 0.7682\nEpoch 361/500\n3304/3304 [==============================] - 13s 4ms/step - loss: 0.9868 - accuracy: 0.7710 - val_loss: 0.9987 - val_accuracy: 0.7682\nEpoch 362/500\n3304/3304 [==============================] - 13s 4ms/step - loss: 0.9867 - accuracy: 0.7710 - val_loss: 0.9986 - val_accuracy: 0.7682\nEpoch 363/500\n3304/3304 [==============================] - 13s 4ms/step - loss: 0.9866 - accuracy: 0.7710 - val_loss: 0.9986 - val_accuracy: 0.7682\nEpoch 364/500\n3304/3304 [==============================] - 13s 4ms/step - loss: 0.9865 - accuracy: 0.7710 - val_loss: 0.9986 - val_accuracy: 0.7682\nEpoch 365/500\n3304/3304 [==============================] - 13s 4ms/step - loss: 0.9864 - accuracy: 0.7710 - val_loss: 0.9986 - val_accuracy: 0.7682\nEpoch 366/500\n3304/3304 [==============================] - 13s 4ms/step - loss: 0.9863 - accuracy: 0.7710 - val_loss: 0.9985 - val_accuracy: 0.7682\nEpoch 367/500\n3304/3304 [==============================] - 13s 4ms/step - loss: 0.9862 - accuracy: 0.7711 - val_loss: 0.9985 - val_accuracy: 0.7682\nEpoch 368/500\n3304/3304 [==============================] - 13s 4ms/step - loss: 0.9861 - accuracy: 0.7711 - val_loss: 0.9985 - val_accuracy: 0.7682\nEpoch 369/500\n3304/3304 [==============================] - 13s 4ms/step - loss: 0.9861 - accuracy: 0.7711 - val_loss: 0.9984 - val_accuracy: 0.7682\nEpoch 370/500\n3304/3304 [==============================] - 13s 4ms/step - loss: 0.9860 - accuracy: 0.7711 - val_loss: 0.9984 - val_accuracy: 0.7682\nEpoch 371/500\n3304/3304 [==============================] - 14s 4ms/step - loss: 0.9859 - accuracy: 0.7711 - val_loss: 0.9984 - val_accuracy: 0.7682\nEpoch 372/500\n3304/3304 [==============================] - 13s 4ms/step - loss: 0.9858 - accuracy: 0.7711 - val_loss: 0.9983 - val_accuracy: 0.7682\nEpoch 373/500\n3304/3304 [==============================] - 13s 4ms/step - loss: 0.9857 - accuracy: 0.7712 - val_loss: 0.9983 - val_accuracy: 0.7682\nEpoch 374/500\n3304/3304 [==============================] - 13s 4ms/step - loss: 0.9856 - accuracy: 0.7712 - val_loss: 0.9983 - val_accuracy: 0.7682\nEpoch 375/500\n3304/3304 [==============================] - 13s 4ms/step - loss: 0.9855 - accuracy: 0.7712 - val_loss: 0.9982 - val_accuracy: 0.7682\nEpoch 376/500\n3304/3304 [==============================] - 13s 4ms/step - loss: 0.9854 - accuracy: 0.7712 - val_loss: 0.9982 - val_accuracy: 0.7682\nEpoch 377/500\n3304/3304 [==============================] - 13s 4ms/step - loss: 0.9853 - accuracy: 0.7712 - val_loss: 0.9982 - val_accuracy: 0.7682\nEpoch 378/500\n3304/3304 [==============================] - 13s 4ms/step - loss: 0.9852 - accuracy: 0.7712 - val_loss: 0.9981 - val_accuracy: 0.7682\nEpoch 379/500\n3304/3304 [==============================] - 13s 4ms/step - loss: 0.9851 - accuracy: 0.7713 - val_loss: 0.9981 - val_accuracy: 0.7682\nEpoch 380/500\n3304/3304 [==============================] - 13s 4ms/step - loss: 0.9850 - accuracy: 0.7713 - val_loss: 0.9981 - val_accuracy: 0.7682\nEpoch 381/500\n3304/3304 [==============================] - 13s 4ms/step - loss: 0.9849 - accuracy: 0.7713 - val_loss: 0.9980 - val_accuracy: 0.7682\nEpoch 382/500\n3304/3304 [==============================] - 13s 4ms/step - loss: 0.9848 - accuracy: 0.7713 - val_loss: 0.9980 - val_accuracy: 0.7682\nEpoch 383/500\n3304/3304 [==============================] - 13s 4ms/step - loss: 0.9847 - accuracy: 0.7713 - val_loss: 0.9980 - val_accuracy: 0.7682\nEpoch 384/500\n3304/3304 [==============================] - 13s 4ms/step - loss: 0.9846 - accuracy: 0.7713 - val_loss: 0.9979 - val_accuracy: 0.7683\nEpoch 385/500\n3304/3304 [==============================] - 13s 4ms/step - loss: 0.9846 - accuracy: 0.7713 - val_loss: 0.9979 - val_accuracy: 0.7683\nEpoch 386/500\n3304/3304 [==============================] - 13s 4ms/step - loss: 0.9845 - accuracy: 0.7713 - val_loss: 0.9979 - val_accuracy: 0.7682\nEpoch 387/500\n3304/3304 [==============================] - 13s 4ms/step - loss: 0.9844 - accuracy: 0.7714 - val_loss: 0.9979 - val_accuracy: 0.7682\nEpoch 388/500\n3304/3304 [==============================] - 13s 4ms/step - loss: 0.9843 - accuracy: 0.7714 - val_loss: 0.9978 - val_accuracy: 0.7682\nEpoch 389/500\n3304/3304 [==============================] - 13s 4ms/step - loss: 0.9842 - accuracy: 0.7714 - val_loss: 0.9978 - val_accuracy: 0.7683\nEpoch 390/500\n3304/3304 [==============================] - 13s 4ms/step - loss: 0.9841 - accuracy: 0.7714 - val_loss: 0.9978 - val_accuracy: 0.7683\nEpoch 391/500\n3304/3304 [==============================] - 13s 4ms/step - loss: 0.9840 - accuracy: 0.7714 - val_loss: 0.9977 - val_accuracy: 0.7683\nEpoch 392/500\n3304/3304 [==============================] - 13s 4ms/step - loss: 0.9839 - accuracy: 0.7714 - val_loss: 0.9977 - val_accuracy: 0.7683\nEpoch 393/500\n3304/3304 [==============================] - 13s 4ms/step - loss: 0.9838 - accuracy: 0.7714 - val_loss: 0.9977 - val_accuracy: 0.7683\nEpoch 394/500\n3304/3304 [==============================] - 13s 4ms/step - loss: 0.9837 - accuracy: 0.7714 - val_loss: 0.9976 - val_accuracy: 0.7683\nEpoch 395/500\n3304/3304 [==============================] - 13s 4ms/step - loss: 0.9836 - accuracy: 0.7715 - val_loss: 0.9976 - val_accuracy: 0.7683\nEpoch 396/500\n3304/3304 [==============================] - 13s 4ms/step - loss: 0.9835 - accuracy: 0.7715 - val_loss: 0.9976 - val_accuracy: 0.7683\nEpoch 397/500\n3304/3304 [==============================] - 13s 4ms/step - loss: 0.9834 - accuracy: 0.7715 - val_loss: 0.9975 - val_accuracy: 0.7683\nEpoch 398/500\n3304/3304 [==============================] - 13s 4ms/step - loss: 0.9834 - accuracy: 0.7715 - val_loss: 0.9975 - val_accuracy: 0.7683\nEpoch 399/500\n3304/3304 [==============================] - 13s 4ms/step - loss: 0.9833 - accuracy: 0.7715 - val_loss: 0.9975 - val_accuracy: 0.7683\nEpoch 400/500\n3304/3304 [==============================] - 13s 4ms/step - loss: 0.9832 - accuracy: 0.7715 - val_loss: 0.9975 - val_accuracy: 0.7683\nEpoch 401/500\n3304/3304 [==============================] - 13s 4ms/step - loss: 0.9831 - accuracy: 0.7715 - val_loss: 0.9974 - val_accuracy: 0.7683\nEpoch 402/500\n3304/3304 [==============================] - 12s 4ms/step - loss: 0.9830 - accuracy: 0.7715 - val_loss: 0.9974 - val_accuracy: 0.7683\nEpoch 403/500\n3304/3304 [==============================] - 13s 4ms/step - loss: 0.9829 - accuracy: 0.7715 - val_loss: 0.9974 - val_accuracy: 0.7683\nEpoch 404/500\n3304/3304 [==============================] - 14s 4ms/step - loss: 0.9828 - accuracy: 0.7715 - val_loss: 0.9973 - val_accuracy: 0.7683\nEpoch 405/500\n3304/3304 [==============================] - 13s 4ms/step - loss: 0.9827 - accuracy: 0.7716 - val_loss: 0.9973 - val_accuracy: 0.7683\nEpoch 406/500\n3304/3304 [==============================] - 13s 4ms/step - loss: 0.9826 - accuracy: 0.7716 - val_loss: 0.9973 - val_accuracy: 0.7683\nEpoch 407/500\n3304/3304 [==============================] - 13s 4ms/step - loss: 0.9825 - accuracy: 0.7716 - val_loss: 0.9972 - val_accuracy: 0.7683\nEpoch 408/500\n3304/3304 [==============================] - 13s 4ms/step - loss: 0.9824 - accuracy: 0.7716 - val_loss: 0.9972 - val_accuracy: 0.7683\nEpoch 409/500\n3304/3304 [==============================] - 13s 4ms/step - loss: 0.9824 - accuracy: 0.7716 - val_loss: 0.9972 - val_accuracy: 0.7683\nEpoch 410/500\n3304/3304 [==============================] - 13s 4ms/step - loss: 0.9823 - accuracy: 0.7716 - val_loss: 0.9972 - val_accuracy: 0.7683\nEpoch 411/500\n3304/3304 [==============================] - 13s 4ms/step - loss: 0.9822 - accuracy: 0.7716 - val_loss: 0.9971 - val_accuracy: 0.7683\nEpoch 412/500\n3304/3304 [==============================] - 13s 4ms/step - loss: 0.9821 - accuracy: 0.7716 - val_loss: 0.9971 - val_accuracy: 0.7684\nEpoch 413/500\n3304/3304 [==============================] - 13s 4ms/step - loss: 0.9820 - accuracy: 0.7717 - val_loss: 0.9971 - val_accuracy: 0.7684\nEpoch 414/500\n3304/3304 [==============================] - 12s 4ms/step - loss: 0.9819 - accuracy: 0.7717 - val_loss: 0.9970 - val_accuracy: 0.7684\nEpoch 415/500\n3304/3304 [==============================] - 13s 4ms/step - loss: 0.9818 - accuracy: 0.7717 - val_loss: 0.9970 - val_accuracy: 0.7684\nEpoch 416/500\n3304/3304 [==============================] - 13s 4ms/step - loss: 0.9817 - accuracy: 0.7717 - val_loss: 0.9970 - val_accuracy: 0.7684\nEpoch 417/500\n3304/3304 [==============================] - 13s 4ms/step - loss: 0.9816 - accuracy: 0.7717 - val_loss: 0.9970 - val_accuracy: 0.7684\nEpoch 418/500\n3304/3304 [==============================] - 13s 4ms/step - loss: 0.9815 - accuracy: 0.7717 - val_loss: 0.9969 - val_accuracy: 0.7684\nEpoch 419/500\n3304/3304 [==============================] - 13s 4ms/step - loss: 0.9815 - accuracy: 0.7717 - val_loss: 0.9969 - val_accuracy: 0.7684\nEpoch 420/500\n3304/3304 [==============================] - 13s 4ms/step - loss: 0.9814 - accuracy: 0.7718 - val_loss: 0.9969 - val_accuracy: 0.7684\nEpoch 421/500\n3304/3304 [==============================] - 13s 4ms/step - loss: 0.9813 - accuracy: 0.7718 - val_loss: 0.9968 - val_accuracy: 0.7685\nEpoch 422/500\n3304/3304 [==============================] - 13s 4ms/step - loss: 0.9812 - accuracy: 0.7718 - val_loss: 0.9968 - val_accuracy: 0.7685\nEpoch 423/500\n3304/3304 [==============================] - 13s 4ms/step - loss: 0.9811 - accuracy: 0.7718 - val_loss: 0.9968 - val_accuracy: 0.7685\nEpoch 424/500\n3304/3304 [==============================] - 13s 4ms/step - loss: 0.9810 - accuracy: 0.7718 - val_loss: 0.9968 - val_accuracy: 0.7685\nEpoch 425/500\n3304/3304 [==============================] - 13s 4ms/step - loss: 0.9809 - accuracy: 0.7718 - val_loss: 0.9967 - val_accuracy: 0.7685\nEpoch 426/500\n3304/3304 [==============================] - 13s 4ms/step - loss: 0.9808 - accuracy: 0.7718 - val_loss: 0.9967 - val_accuracy: 0.7685\nEpoch 427/500\n3304/3304 [==============================] - 13s 4ms/step - loss: 0.9807 - accuracy: 0.7718 - val_loss: 0.9967 - val_accuracy: 0.7685\nEpoch 428/500\n3304/3304 [==============================] - 13s 4ms/step - loss: 0.9806 - accuracy: 0.7718 - val_loss: 0.9966 - val_accuracy: 0.7685\nEpoch 429/500\n3304/3304 [==============================] - 13s 4ms/step - loss: 0.9806 - accuracy: 0.7719 - val_loss: 0.9966 - val_accuracy: 0.7685\nEpoch 430/500\n3304/3304 [==============================] - 13s 4ms/step - loss: 0.9805 - accuracy: 0.7719 - val_loss: 0.9966 - val_accuracy: 0.7685\nEpoch 431/500\n3304/3304 [==============================] - 13s 4ms/step - loss: 0.9804 - accuracy: 0.7719 - val_loss: 0.9966 - val_accuracy: 0.7685\nEpoch 432/500\n3304/3304 [==============================] - 13s 4ms/step - loss: 0.9803 - accuracy: 0.7719 - val_loss: 0.9965 - val_accuracy: 0.7685\nEpoch 433/500\n3304/3304 [==============================] - 13s 4ms/step - loss: 0.9802 - accuracy: 0.7719 - val_loss: 0.9965 - val_accuracy: 0.7685\nEpoch 434/500\n3304/3304 [==============================] - 13s 4ms/step - loss: 0.9801 - accuracy: 0.7719 - val_loss: 0.9965 - val_accuracy: 0.7685\nEpoch 435/500\n3304/3304 [==============================] - 13s 4ms/step - loss: 0.9800 - accuracy: 0.7720 - val_loss: 0.9964 - val_accuracy: 0.7685\nEpoch 436/500\n3304/3304 [==============================] - 12s 4ms/step - loss: 0.9799 - accuracy: 0.7720 - val_loss: 0.9964 - val_accuracy: 0.7685\nEpoch 437/500\n3304/3304 [==============================] - 13s 4ms/step - loss: 0.9798 - accuracy: 0.7720 - val_loss: 0.9964 - val_accuracy: 0.7685\nEpoch 438/500\n3304/3304 [==============================] - 13s 4ms/step - loss: 0.9798 - accuracy: 0.7720 - val_loss: 0.9964 - val_accuracy: 0.7685\nEpoch 439/500\n3304/3304 [==============================] - 13s 4ms/step - loss: 0.9797 - accuracy: 0.7720 - val_loss: 0.9963 - val_accuracy: 0.7685\nEpoch 440/500\n3304/3304 [==============================] - 13s 4ms/step - loss: 0.9796 - accuracy: 0.7720 - val_loss: 0.9963 - val_accuracy: 0.7685\nEpoch 441/500\n3304/3304 [==============================] - 13s 4ms/step - loss: 0.9795 - accuracy: 0.7721 - val_loss: 0.9963 - val_accuracy: 0.7685\nEpoch 442/500\n3304/3304 [==============================] - 13s 4ms/step - loss: 0.9794 - accuracy: 0.7721 - val_loss: 0.9962 - val_accuracy: 0.7685\nEpoch 443/500\n3304/3304 [==============================] - 13s 4ms/step - loss: 0.9793 - accuracy: 0.7721 - val_loss: 0.9962 - val_accuracy: 0.7685\nEpoch 444/500\n3304/3304 [==============================] - 13s 4ms/step - loss: 0.9792 - accuracy: 0.7721 - val_loss: 0.9962 - val_accuracy: 0.7685\nEpoch 445/500\n3304/3304 [==============================] - 14s 4ms/step - loss: 0.9791 - accuracy: 0.7721 - val_loss: 0.9962 - val_accuracy: 0.7685\nEpoch 446/500\n3304/3304 [==============================] - 13s 4ms/step - loss: 0.9791 - accuracy: 0.7721 - val_loss: 0.9961 - val_accuracy: 0.7685\nEpoch 447/500\n3304/3304 [==============================] - 13s 4ms/step - loss: 0.9790 - accuracy: 0.7722 - val_loss: 0.9961 - val_accuracy: 0.7685\nEpoch 448/500\n3304/3304 [==============================] - 13s 4ms/step - loss: 0.9789 - accuracy: 0.7722 - val_loss: 0.9961 - val_accuracy: 0.7685\nEpoch 449/500\n3304/3304 [==============================] - 13s 4ms/step - loss: 0.9788 - accuracy: 0.7722 - val_loss: 0.9960 - val_accuracy: 0.7685\nEpoch 450/500\n3304/3304 [==============================] - 13s 4ms/step - loss: 0.9787 - accuracy: 0.7722 - val_loss: 0.9960 - val_accuracy: 0.7685\nEpoch 451/500\n3304/3304 [==============================] - 13s 4ms/step - loss: 0.9786 - accuracy: 0.7722 - val_loss: 0.9960 - val_accuracy: 0.7685\nEpoch 452/500\n3304/3304 [==============================] - 13s 4ms/step - loss: 0.9785 - accuracy: 0.7722 - val_loss: 0.9960 - val_accuracy: 0.7685\nEpoch 453/500\n3304/3304 [==============================] - 13s 4ms/step - loss: 0.9784 - accuracy: 0.7722 - val_loss: 0.9959 - val_accuracy: 0.7685\nEpoch 454/500\n3304/3304 [==============================] - 13s 4ms/step - loss: 0.9784 - accuracy: 0.7722 - val_loss: 0.9959 - val_accuracy: 0.7685\nEpoch 455/500\n3304/3304 [==============================] - 13s 4ms/step - loss: 0.9783 - accuracy: 0.7723 - val_loss: 0.9959 - val_accuracy: 0.7685\nEpoch 456/500\n3304/3304 [==============================] - 13s 4ms/step - loss: 0.9782 - accuracy: 0.7723 - val_loss: 0.9959 - val_accuracy: 0.7685\nEpoch 457/500\n3304/3304 [==============================] - 13s 4ms/step - loss: 0.9781 - accuracy: 0.7723 - val_loss: 0.9958 - val_accuracy: 0.7686\nEpoch 458/500\n3304/3304 [==============================] - 13s 4ms/step - loss: 0.9780 - accuracy: 0.7723 - val_loss: 0.9958 - val_accuracy: 0.7686\nEpoch 459/500\n3304/3304 [==============================] - 13s 4ms/step - loss: 0.9779 - accuracy: 0.7723 - val_loss: 0.9958 - val_accuracy: 0.7686\nEpoch 460/500\n3304/3304 [==============================] - 13s 4ms/step - loss: 0.9778 - accuracy: 0.7723 - val_loss: 0.9957 - val_accuracy: 0.7685\nEpoch 461/500\n3304/3304 [==============================] - 13s 4ms/step - loss: 0.9777 - accuracy: 0.7723 - val_loss: 0.9957 - val_accuracy: 0.7686\nEpoch 462/500\n3304/3304 [==============================] - 13s 4ms/step - loss: 0.9777 - accuracy: 0.7724 - val_loss: 0.9957 - val_accuracy: 0.7686\nEpoch 463/500\n3304/3304 [==============================] - 13s 4ms/step - loss: 0.9776 - accuracy: 0.7724 - val_loss: 0.9957 - val_accuracy: 0.7686\nEpoch 464/500\n3304/3304 [==============================] - 13s 4ms/step - loss: 0.9775 - accuracy: 0.7724 - val_loss: 0.9956 - val_accuracy: 0.7686\nEpoch 465/500\n3304/3304 [==============================] - 13s 4ms/step - loss: 0.9774 - accuracy: 0.7724 - val_loss: 0.9956 - val_accuracy: 0.7686\nEpoch 466/500\n3304/3304 [==============================] - 13s 4ms/step - loss: 0.9773 - accuracy: 0.7724 - val_loss: 0.9956 - val_accuracy: 0.7686\nEpoch 467/500\n3304/3304 [==============================] - 13s 4ms/step - loss: 0.9772 - accuracy: 0.7724 - val_loss: 0.9956 - val_accuracy: 0.7686\nEpoch 468/500\n3304/3304 [==============================] - 13s 4ms/step - loss: 0.9771 - accuracy: 0.7725 - val_loss: 0.9955 - val_accuracy: 0.7686\nEpoch 469/500\n3304/3304 [==============================] - 13s 4ms/step - loss: 0.9770 - accuracy: 0.7725 - val_loss: 0.9955 - val_accuracy: 0.7686\nEpoch 470/500\n3304/3304 [==============================] - 13s 4ms/step - loss: 0.9770 - accuracy: 0.7725 - val_loss: 0.9955 - val_accuracy: 0.7686\nEpoch 471/500\n3304/3304 [==============================] - 12s 4ms/step - loss: 0.9769 - accuracy: 0.7725 - val_loss: 0.9955 - val_accuracy: 0.7686\nEpoch 472/500\n3304/3304 [==============================] - 13s 4ms/step - loss: 0.9768 - accuracy: 0.7725 - val_loss: 0.9954 - val_accuracy: 0.7686\nEpoch 473/500\n3304/3304 [==============================] - 13s 4ms/step - loss: 0.9767 - accuracy: 0.7725 - val_loss: 0.9954 - val_accuracy: 0.7687\nEpoch 474/500\n3304/3304 [==============================] - 14s 4ms/step - loss: 0.9766 - accuracy: 0.7726 - val_loss: 0.9954 - val_accuracy: 0.7687\nEpoch 475/500\n3304/3304 [==============================] - 13s 4ms/step - loss: 0.9765 - accuracy: 0.7726 - val_loss: 0.9953 - val_accuracy: 0.7687\nEpoch 476/500\n3304/3304 [==============================] - 13s 4ms/step - loss: 0.9764 - accuracy: 0.7726 - val_loss: 0.9953 - val_accuracy: 0.7687\nEpoch 477/500\n3304/3304 [==============================] - 13s 4ms/step - loss: 0.9764 - accuracy: 0.7726 - val_loss: 0.9953 - val_accuracy: 0.7687\nEpoch 478/500\n3304/3304 [==============================] - 13s 4ms/step - loss: 0.9763 - accuracy: 0.7726 - val_loss: 0.9953 - val_accuracy: 0.7687\nEpoch 479/500\n3304/3304 [==============================] - 13s 4ms/step - loss: 0.9762 - accuracy: 0.7726 - val_loss: 0.9952 - val_accuracy: 0.7687\nEpoch 480/500\n3304/3304 [==============================] - 13s 4ms/step - loss: 0.9761 - accuracy: 0.7726 - val_loss: 0.9952 - val_accuracy: 0.7687\nEpoch 481/500\n3304/3304 [==============================] - 13s 4ms/step - loss: 0.9760 - accuracy: 0.7726 - val_loss: 0.9952 - val_accuracy: 0.7687\nEpoch 482/500\n3304/3304 [==============================] - 13s 4ms/step - loss: 0.9759 - accuracy: 0.7727 - val_loss: 0.9952 - val_accuracy: 0.7687\nEpoch 483/500\n3304/3304 [==============================] - 13s 4ms/step - loss: 0.9758 - accuracy: 0.7727 - val_loss: 0.9951 - val_accuracy: 0.7687\nEpoch 484/500\n3304/3304 [==============================] - 13s 4ms/step - loss: 0.9758 - accuracy: 0.7727 - val_loss: 0.9951 - val_accuracy: 0.7687\nEpoch 485/500\n3304/3304 [==============================] - 13s 4ms/step - loss: 0.9757 - accuracy: 0.7727 - val_loss: 0.9951 - val_accuracy: 0.7687\nEpoch 486/500\n3304/3304 [==============================] - 13s 4ms/step - loss: 0.9756 - accuracy: 0.7727 - val_loss: 0.9951 - val_accuracy: 0.7687\nEpoch 487/500\n3304/3304 [==============================] - 13s 4ms/step - loss: 0.9755 - accuracy: 0.7727 - val_loss: 0.9950 - val_accuracy: 0.7688\nEpoch 488/500\n3304/3304 [==============================] - 13s 4ms/step - loss: 0.9754 - accuracy: 0.7728 - val_loss: 0.9950 - val_accuracy: 0.7688\nEpoch 489/500\n3304/3304 [==============================] - 12s 4ms/step - loss: 0.9753 - accuracy: 0.7728 - val_loss: 0.9950 - val_accuracy: 0.7688\nEpoch 490/500\n3304/3304 [==============================] - 13s 4ms/step - loss: 0.9752 - accuracy: 0.7728 - val_loss: 0.9950 - val_accuracy: 0.7688\nEpoch 491/500\n3304/3304 [==============================] - 13s 4ms/step - loss: 0.9752 - accuracy: 0.7728 - val_loss: 0.9949 - val_accuracy: 0.7688\nEpoch 492/500\n3304/3304 [==============================] - 13s 4ms/step - loss: 0.9751 - accuracy: 0.7728 - val_loss: 0.9949 - val_accuracy: 0.7688\nEpoch 493/500\n3304/3304 [==============================] - 13s 4ms/step - loss: 0.9750 - accuracy: 0.7728 - val_loss: 0.9949 - val_accuracy: 0.7688\nEpoch 494/500\n3304/3304 [==============================] - 13s 4ms/step - loss: 0.9749 - accuracy: 0.7728 - val_loss: 0.9949 - val_accuracy: 0.7688\nEpoch 495/500\n3304/3304 [==============================] - 13s 4ms/step - loss: 0.9748 - accuracy: 0.7728 - val_loss: 0.9948 - val_accuracy: 0.7688\nEpoch 496/500\n3304/3304 [==============================] - 13s 4ms/step - loss: 0.9747 - accuracy: 0.7729 - val_loss: 0.9948 - val_accuracy: 0.7688\nEpoch 497/500\n3304/3304 [==============================] - 13s 4ms/step - loss: 0.9747 - accuracy: 0.7729 - val_loss: 0.9948 - val_accuracy: 0.7688\nEpoch 498/500\n3304/3304 [==============================] - 13s 4ms/step - loss: 0.9746 - accuracy: 0.7729 - val_loss: 0.9948 - val_accuracy: 0.7689\nEpoch 499/500\n3304/3304 [==============================] - 13s 4ms/step - loss: 0.9745 - accuracy: 0.7729 - val_loss: 0.9947 - val_accuracy: 0.7689\nEpoch 500/500\n3304/3304 [==============================] - 13s 4ms/step - loss: 0.9744 - accuracy: 0.7729 - val_loss: 0.9947 - val_accuracy: 0.7689\n","output_type":"stream"},{"execution_count":29,"output_type":"execute_result","data":{"text/plain":"<tensorflow.python.keras.callbacks.History at 0x7f76ff5bf4d0>"},"metadata":{}}]},{"cell_type":"code","source":"# X_test = X_test.reshape(X_test.shape[0],X_test.shape[1])\n# y_pred = np.argmax(model.predict(X_test),axis=1)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model.save('./Model1_3.h5',save_format='h5')","metadata":{"trusted":true},"execution_count":30,"outputs":[]},{"cell_type":"code","source":"accuracy_score(y_test, np.argmax(model.predict(X_test),axis=1))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"with open('../input/test-encoding/encoding_test.npy', 'rb') as f:\n    test = np.load(f)","metadata":{"trusted":true},"execution_count":31,"outputs":[]},{"cell_type":"code","source":"X_test = test.reshape(test.shape[0],test.shape[1])","metadata":{"trusted":true},"execution_count":32,"outputs":[]},{"cell_type":"code","source":"y_pred = np.argmax(model.predict(X_test),axis=1)","metadata":{"trusted":true},"execution_count":33,"outputs":[]},{"cell_type":"code","source":"t = pd.read_csv('../input/amazon-ml-challenge-2021-hackerearth/test.csv',escapechar='\\\\', quoting=3)","metadata":{"trusted":true},"execution_count":34,"outputs":[]},{"cell_type":"code","source":"t.columns","metadata":{"trusted":true},"execution_count":35,"outputs":[{"execution_count":35,"output_type":"execute_result","data":{"text/plain":"Index(['PRODUCT_ID', 'TITLE', 'DESCRIPTION', 'BULLET_POINTS', 'BRAND'], dtype='object')"},"metadata":{}}]},{"cell_type":"code","source":"invert = {v: k for k, v in label.items()}","metadata":{"trusted":true},"execution_count":36,"outputs":[]},{"cell_type":"code","source":"predd = [invert[i] for i in y_pred]","metadata":{"trusted":true},"execution_count":37,"outputs":[]},{"cell_type":"code","source":"sub = pd.DataFrame({'PRODUCT_ID':t['PRODUCT_ID'].values,'BROWSE_NODE_ID':predd})","metadata":{"trusted":true},"execution_count":38,"outputs":[]},{"cell_type":"code","source":"sub.to_csv('sub4.csv',index=False)","metadata":{"trusted":true},"execution_count":39,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}